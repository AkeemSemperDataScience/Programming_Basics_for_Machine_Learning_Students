{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DATA3320/DATA3320_1231/blob/main/workbooks/Lecture13_workbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf_9Uw8VykQ0"
      },
      "source": [
        "# Lecture 13 Workbook - Describing One Variable\n",
        "\n",
        "The first step on our statistical journey is to look at how we can describe one variable at a time.\n",
        "\n",
        "There are a few things that we can focus on here:\n",
        "<ul>\n",
        "<li> Loading data into Python.\n",
        "<li> Manipulating data structures containing data.\n",
        "<li> Basic statistics describing data.\n",
        "<li> Distributions and visualizations.\n",
        "</ul>\n",
        "\n",
        "In short, we want to be able to load in a dataset, manipulate it to get what we care about, and look at the data (starting with one variable) to see what it says. This is a near universal starting point for doing machine learning, it all starts with the data, so gaining some understanding of that data will help us out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqGp9XLfykQ3"
      },
      "outputs": [],
      "source": [
        "# import libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "kry1oujkykQ4"
      },
      "source": [
        "## Storing Data - Dataframes\n",
        "\n",
        "We'll load the Titanic data from last time into a dataframe again. Dataframes are one of our most commonly used data structures (thing that stores a bunch of data in an organized way). We can think of a dataframe as a well formatted spreadsheet:\n",
        "<ul>\n",
        "<li> Each column represents one feature (variable) that is part of our data.\n",
        "<li> Each row represents one instance (example) of whatever we're looking at.\n",
        "<li> Each cell is one value.\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ii0-NkwykQ5"
      },
      "outputs": [],
      "source": [
        "# Load some data\n",
        "\n",
        "\n",
        "# show the first five records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voq4inTMykQ5"
      },
      "source": [
        "### Slicing Dataframes\n",
        "\n",
        "We can select different parts of a dataframe at a time. Most commonly, we want to get one or more of the columns. We can use the column names to get what we want. There are multiple ways to do this, but we will almost always settle on the last one.\n",
        "\n",
        "Suppose we want the column of \"Survived\" - 0 for Leo, 1 for Kate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9vUDKwHykQ6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXIGrRMlykQ6"
      },
      "source": [
        "Challenge - print multiple columns. Such as Survived and Age!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH3BtNBVykQ6"
      },
      "outputs": [],
      "source": [
        "# Select Multiple Columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fNjsgxyykQ6"
      },
      "source": [
        "### Slicing by Rows\n",
        "\n",
        "We can also select rows from a dataframe. This is generally less important for most of the things that we do. We can select the specific rows we want, or give a condition to filter by. This is effectively the same as using the filter feature in Excel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGy6ojBBykQ7"
      },
      "outputs": [],
      "source": [
        "# Get the first 5 rows, like the head() command.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DSHrKHDykQ7"
      },
      "outputs": [],
      "source": [
        "# Get all the dead people\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54I022j6ykQ7"
      },
      "source": [
        "This can be used to select only the portion of data that we want in a given scenario. For example, if we only wanted Titanic survivors that are in the 18 to 34 age range (pretend we are trying to sell TV ads), we can select that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxIAMLEuykQ7"
      },
      "outputs": [],
      "source": [
        "# First filter survive\n",
        "\n",
        "# Now do age, first the lower limit\n",
        "\n",
        "#df_surv = df_surv[df_surv[\"Age\"] >= 18]\n",
        "# Upper limit, and put the result in a well named variable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b628rJGtykQ8"
      },
      "source": [
        "## Types of Data\n",
        "\n",
        "We have several different types of data that we may need to deal with. The most important split is the difference between categorical data and numerical data. This is one thing that we need to be very comfortable with:\n",
        "<ul>\n",
        "<li> Numerical Data - typically a measurement, reading, or value that is numerical. E.g. Net worth, age, temperature, belt size, etc...\n",
        "    <ul>\n",
        "    <li> Rule of thumb - if you can plot a value on a number line and \"do math\" to it - e.g. compare greater/lesser, add, divide - then it is probably numerical.\n",
        "    </ul>\n",
        "<li> Categorical Data - typically a label, descriptor, or group indicator. E.g. hair color, land zoning, car make, type of tree, etc...\n",
        "    <ul>\n",
        "    <li> Rule of thumb - if you would \"group by\" a value, it is normally categorical.\n",
        "    </ul>\n",
        "</ul>\n",
        "\n",
        "Usually determining which data type our data falls into is relatively easy, but there are some scenarios where it isn't. Most notably, numbers are often used to denote group types, so they sometimes act as categorical values. For example, if we were to group people by their nationality and label those groups 1, 2, 3, etc... that is a use of a numerical variable as a categorical value. We will need to do things like this later on.\n",
        "\n",
        "#### Python Data Types\n",
        "\n",
        "Every programming language has a few built in data types that it naturally supports. Some important and common ones are:\n",
        "<ul>\n",
        "<li> String - text.\n",
        "<li> Integer - number without decimals.\n",
        "<li> Float - number with decimals.\n",
        "<li> Bool - true/false.\n",
        "</ul>\n",
        "\n",
        "The \"type()\" function will show the type of any object.\n",
        "\n",
        "<b>Note:</b> Python is what we called a weakly typed language, which basically means that an individual varaible can take on any type of value (this is in comparison to a strongly typed language, where if you create an integer varaible, it can only be an integer). This has the advantage of making things easy to do, as there's no restrictions on what you can do with a variable; however, it can also lead to confusion as it makes it easier to make an error such as putting a text value in a varaible when you are expecting a number. Using clear variable names is the most simple way to protect against this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hXLbJweykQ8"
      },
      "outputs": [],
      "source": [
        "print(type(\"1.23\"))\n",
        "print(type(123))\n",
        "print(type(1.23))\n",
        "print(type(False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbaSmZdCykQ8"
      },
      "source": [
        "## Counts of Categorical Variables\n",
        "\n",
        "When dealing with categorical variables the most important thing that we can know is how many times each value occurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDrG0GPdykQ8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wEb5KMCykQ9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRE4EJ7CykQ9"
      },
      "source": [
        "#### Countplots\n",
        "\n",
        "We can also use a very simple visualization to see the counts broken down. Each tab holds the same countplot, the difference in the second one is that we added an argument for \"hue\", which is a common argument in seaborn graphs that separates the data by whatever you put there. Here we gave it the \"Survived\" variable, so each of the bars is split into survived/died subsets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4ltAmKwykQ9"
      },
      "source": [
        "## Countplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdQC8Fy2ykQ9"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: \"A countplot\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBpjyjK7ykQ-"
      },
      "source": [
        "## Countplot - Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1LE-hZNykQ-"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: \"A countplot\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhjTUuEPykQ-"
      },
      "source": [
        "## Distribution of Numerical Variables\n",
        "\n",
        "Probably the most critical thing we can know about a numerical variable is its distribution - or how many times different values occur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vENFWLCykQ-"
      },
      "source": [
        "We can also get these statistics individually. This time I added print statements, this just makes the program print more than one output, if all the print statements are left our we'd only get the last one.\n",
        "\n",
        "This is one place where we can easily see multiple ways to do things, which is very common in programming. Specifically, we have several sets of functions that do basic math. Here we have an example of probably the two most common ones:\n",
        "<ul>\n",
        "<li> Pandas - the library that provides dataframes for us.\n",
        "<li> Numpy - this library has a bunch of useful math-y stuff.\n",
        "</ul>\n",
        "Note the difference in how the code is structured for each one, this is due to <b><i>where</i></b> these functions come from. The pandas ones are called by stating DATFRAME.FUNCTION() - this is because the functions \"are part of\" pandas, so we can tell it to basically \"find the mean function for this object (the df)\" and the program will look inside of Pandas for that thing. This works because the dataframe has its own mean/std/count function built into it. The numpy ones are more generic, and we call them by saying LIBRARY.FUNCTION(DATA). This is because these are not part of the dataframe, we are calling a generic function and feeding it our data. We don't need a dataframe to use this, we can feed it (almost) any data - lists, arrays, series, etc... since it is not part of an object. This basic split is something that is pretty universal in most programming languages, it feels arbitrary at first but it does become natural over time.\n",
        "\n",
        "<b>Note:</b> the median below and the 50% above are the same. The median is the value \"in the middle\" - half of the values are higher, half lower.\n",
        "\n",
        "#### Examples of Basic Stats Functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmQ39JLJykQ-"
      },
      "source": [
        "::: {.panel-tabset group=\"python\"}\n",
        "\n",
        "## Describe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyNViHaBykQ-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYDUSZa3ykQ_"
      },
      "source": [
        "## Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tpVt2S3ykQ_"
      },
      "outputs": [],
      "source": [
        "print(\"Mean: \", df[\"Fare\"].mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuB1jF8qykQ_"
      },
      "source": [
        "## Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heLguiI2ykQ_"
      },
      "outputs": [],
      "source": [
        "print(\"Mean: \", np.mean(df[\"Fare\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhLtG5JoykQ_"
      },
      "source": [
        "## Distributions\n",
        "\n",
        "When looking at a variable, calculating things like the mean or median is useful, but very incomplete. We probably want to know more about the values and how frequently they occur - something called the distribution.\n",
        "\n",
        "Distributions are one of the fundamental concepts of statistics, one that well use constantly. We'll dig into them a bunch more over the next few sessions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdMn7ImrykQ_"
      },
      "source": [
        "### Types of Distributions\n",
        "\n",
        "Distributions commonly follow patterns, and we can use these paterns to help us build an understanding of our own data.\n",
        "\n",
        "We will look more at specific distributions in more detail soon, for now, we can think of distributions as describing the shape of the data, or how it is distributed over the range.\n",
        "\n",
        "#### Histograms\n",
        "\n",
        "The histogram is the most common tool used to examine a distribution. A histogram is a specialized type of bar chart that is always structured in the same way:\n",
        "<ul>\n",
        "<li> The X axis is the variable we are looking at.\n",
        "<li> The Y axis is a count of how many times that value occurs.\n",
        "</ul>\n",
        "\n",
        "Histograms will be one of our most frequently used visualizations - luckily they are pretty simple.\n",
        "\n",
        "#### Seaborn and Graphing\n",
        "\n",
        "There are many, many packages that allow us to draw charts and visualizations in Python. The main one we'll focus on is called Seaborn. Seaborn is a package of graphing and charting tools that makes it relatively easy to make pretty charts.\n",
        "\n",
        "Seaborn is not the only choice, but it is common, pretty, and easy, so we'll stick with it for the most part.\n",
        "\n",
        "There are several types of graphs that we can look at to picture the distribution of our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJmroEp9ykRA"
      },
      "source": [
        "::: {.panel-tabset group=\"python\"}\n",
        "\n",
        "## Histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX5kXlHQykRA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW64hzjWykRA"
      },
      "source": [
        "## PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bt35gOQykRA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlOcN9SoykRA"
      },
      "source": [
        "## CDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmrEoqBPykRA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CveZD1cpykRM"
      },
      "source": [
        "## Hist w/ PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yUpRnQhykRN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWgp_vUbykRN"
      },
      "source": [
        "### Seaborn, Matplotlib, and Graphing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngtYGEfdykRN"
      },
      "source": [
        "We can do something similar with the underlying functionality of Seaborn - matplotlib and pyplot. Matplotlib is the \"granddaddy\" of graphing in Python, and the entire Seaborn package is built on top of it. The mpl stuff is generally less fancy looking and more confusing to use, but we do need to be at least a bit aware of it.\n",
        "\n",
        "Why is this important?\n",
        "<ul>\n",
        "<li> Sometimes we need the \"original\" matplotlib stuff to do things, even when making Seaborn charts.\n",
        "<li> If we are looking for examples/explainations online, there is a high probability that we see some mpl stuff in that code.\n",
        "<li> One of the key things that makes programming a usefull thing is the ability to have functionality that is modular and can be extended (build better things on top of existing code). This is one of the first places where we start to deal with that. In the example below, we should be able to see that code for a histogram, read it, understand the goal, and replace it with a Seaborn histogram shoudl we desire.\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lpb6bdS1ykRN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwd0eJ3zykRO"
      },
      "source": [
        "## Outliers\n",
        "\n",
        "Outliers are values that are \"far outside the norm\", or basically values that fall to the extreme left of extreme right of our distribution.\n",
        "\n",
        "### Dealing with Outliers\n",
        "\n",
        "Dealing with outliers is always a matter of judgement - sometimes an outlier is real and relevant, so we want to keep it in; sometimes an outlier is an error or misleading, so we want to remove it.\n",
        "\n",
        "As a rule of thumb, we can think of what to do outliers like this:\n",
        "<ul>\n",
        "<li> If the outlier is going to help inform our model, and will help create more accurate predictions, we want to leave it in.\n",
        "<li> If the outlier is going to skew our results, and will make predictions less accurate, we want to remove it.\n",
        "</ul>\n",
        "In practice, most outliers are filtered out. Knowing that Elon Musk has 300 billion dollars will rarely be helpful in building a model to predict the net worth of people. Usually this is the case, outliers are very rare, and don't really help in predicting a \"normal\" value.\n",
        "\n",
        "We have ways to automatically (-ish) remove outliers that we'll look at later on in the course. The most simple way to remove outliers is to just create a filter that removes every value that is greater or less than a cutoff. Our histograms can often give us a good idea of what that cutoff should be as we can see it visually on the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVaSspPKykRO"
      },
      "outputs": [],
      "source": [
        "# Try a different value.\n",
        "# Add a filter to get rid of very large outliers.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "ea39297c2a3b8433e0e3c4b620aff79df88eb4bda961dfb2311fbafd7efdbd77"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}