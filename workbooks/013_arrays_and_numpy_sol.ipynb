{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy and Arrays\n",
    "\n",
    "Another of the common libraries and data structures that we commonly use in Python is the Numpy library and the array data structure. Numpy is a library that is used for scientific computing including data science. In particular, arrays are used heavily when creating neural network models in TensorFlow and Keras, which is what we will do towards the end of the machine learning notebooks. \n",
    "\n",
    "## Numpy Library\n",
    "\n",
    "The Numpy library is a Python library that is used for scientific computing, largely for creating arrays and matrices of data for machine learning models. Numpy also includes an extensive library of, largely mathematical, functions that can be applied to arrays and matrices.\n",
    "\n",
    "We typically import numpy with an alias of \"np\", so most code examples you'll see will have \"np.WHATEVER\" for any numpy functions. Like Pandas, this is not a rule, but it is a convention that is used by most data scientists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Arrays\n",
    "\n",
    "Numpy arrays are a data structure that is used to store data, and are largely similar to a list, though a more rigid one. Numpy arrays are used heavily in machine learning models, and are the data structure that is used to store the data that is actually passed into the models.\n",
    "\n",
    "For the most part, numpy arrays will work seamlessly in many of the functions that we use with other data structures. For example, the visualizations of data that we'll use through the machine learning work will make use of lists, series, arrays, or dataframes. \n",
    "\n",
    "![Array](../../images/array.png \"Array\")\n",
    "![Array](../images/array.png \"Array\")\n",
    "\n",
    "### Arrays as a Concept\n",
    "\n",
    "The array is perhaps the most foundational data structure of all, and if we use more lower-level languages such as C, arrays are <i>the</i> data structure that we can use without importing any outside libraries. An array is structurally a lot like a list, but with a few key restrictions and differences:\n",
    "<ul>\n",
    "<li> All elements of an array must be of the same type, whereas a list can contain elements of different types. </li>\n",
    "<li> Arrays are of a fixed size, whereas lists can grow and shrink. Array sizes are declared when created and can't change. </li>\n",
    "<li> The items in an array are mutable, we can modify any value inside an array. </li>\n",
    "<li> Arrays are stored in contiguous memory, whereas lists are not, or may not be. </li>\n",
    "</ul>\n",
    "\n",
    "The final point is one that is mainly irrelevant when using an array in practice, but it is one that explains why arrays were so much more critical in older languages such as C than they are in new high-level languages such as Python. It also helps illustrate the difference between an array and a list, as well as the two types of languages. \n",
    "\n",
    "![Array Memory](../../images/array_memory.png \"Array Memory\")\n",
    "![Array Memory](../images/array_memory.png \"Array Memory\")\n",
    "\n",
    "Because an array is a fixed size, such as 100 integers, the computer can allocate a block of memory that is 100 integers long, and then store the array in that block of memory. This is what is meant by contiguous memory, the array is stored in a single block of memory. Since arrays never shrink or grow, as long as we have the address of the first element in the array, we can calculate the address of any element in the array. We also never need to worry about what happens if we need more space, as that's not possible. This definitive location in memory, leads to a few outcomes:\n",
    "<ul>\n",
    "<li> First, this specific memory address was one of the building blocks of modern data structures such as a list - first adding indexing, then adding flexibility. Needing to manually manage memory is a lot of work, and avoiding doing so is one benefit of using a high-level language such as Python. </li>\n",
    "<li> Second, this is why arrays are so much faster than lists. If we want to access the 50th element of an array, we can calculate the memory address of that element and go directly to it. If we want to access the 50th element of a list, we have to start at the beginning of the list and iterate through it until we get to the 50th element. With a list we need to nagivate from item to item, and ensure we are going to the correct item; with an array, we know by definition where exactly every item is, so accessing each one is extremely fast. </li>\n",
    "</ul>\n",
    "\n",
    "### Array Usage\n",
    "\n",
    "While the restrictions of an array make it less useful than something like a list in many cases, we do still have uses for it, primarily for the final datasets that we actually feed to machine learning models. Since the data we feed in always has consistent types as well as a fixed size, and we really care about efficiency if we have large data that is going to be repeatedly accessed, arrays are a good choice for this. In general, we can do most or all of the preparation of our data while it is stored in dataframes, and then convert it to arrays when we are ready to feed it into a model.\n",
    "\n",
    "We can make some simple arrays, though this step is actually a little more complex than creating a list or a dictionary - since an array needs to be a set size, we need to specify that size at creation. We can do this by passing in values to use in a list, or by using one of the functions to prefill an array with a specific value. We can also specify the type of the array, which we normally do implicitly, by filling it with some object. The types of arrays are the same as the types of variables, so we can have an array of integers, floats, strings, etc. For our purposes, we will virtually always use arrays of floats, as that is what we need to feed into machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[None None None None None None None None None None]\n"
     ]
    }
   ],
   "source": [
    "# Make an array\n",
    "array1 = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "print(array1)\n",
    "\n",
    "# Create an empty array of 20 0's\n",
    "array2 = np.zeros(20)\n",
    "print(array2)\n",
    "\n",
    "# Create an array of 10 empty values\n",
    "array3 = np.full(10, None)\n",
    "print(array3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Array Shape\n",
    "\n",
    "The shape of an array is the number of dimensions that it has, and the size of each dimension. For example, a 1-dimensional array of 10 elements has a shape of (10), a 2-dimensional array of 10 rows and 5 columns has a shape of (10, 5), and a 3-dimensional array of 10 rows, 5 columns, and 2 layers has a shape of (10, 5, 2). We can get the shape with the \"shape\" attribute of an array.\n",
    "\n",
    "Note that the dimensions of a 1 dimension array will show as something like (10,), not (10,1) - the first is an array of 10 items, the second is a 2-dimensional array of 10 rows and 1 column. These two are different and we do need to be careful about the distinction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(20,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(array1.shape)\n",
    "print(array2.shape)\n",
    "print(array3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations on Arrays\n",
    "\n",
    "When we want to perform some operation on the data in an array, we can create loops just like we would with a list. We can also use the built-in functions that are part of the Numpy library, which are generally faster and more efficient than using a loop. For simple operations, we can also just \"math\" on the arrays directly - this will apply the operation to the entire array, and is the fastest and most efficient way to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "After:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: \", array2)\n",
    "array2 += 1\n",
    "print(\"After: \", array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0\n",
      "1 1.0\n",
      "2 1.0\n",
      "3 1.0\n",
      "4 1.0\n",
      "5 1.0\n",
      "6 1.0\n",
      "7 1.0\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 1.0\n",
      "14 1.0\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "18 1.0\n",
      "19 1.0\n"
     ]
    }
   ],
   "source": [
    "for index, item in enumerate(array2):\n",
    "    print(index, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrays from Dataframes\n",
    "\n",
    "Probably the most common way that we'll use arrays is to take prepared data from a dataframe and convert it to an array. Since we already know the size and type of the data, the array can carve itself out a spot in memory and then copy the data over. \n",
    "\n",
    "This is a pretty typical example of what we'd do with arrays when doing some machine learning. We have some data in a dataframe that is ready to be used in machine learning, we split the target and features (what we want to predict from the inputs we use to predict), make them both arrays, and Bob's your uncle. As we can see, the array version is much less reader friendly than the dataframe version, but it is much more efficient to use in a model.\n",
    "\n",
    "In general, an array can be created from pretty much any other data structure, including a list, a tuple, or a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/sportsref_download.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/akeem/Documents/GitHub/Programming_Basics_for_ML/workbooks/013_arrays_and_numpy_sol.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/akeem/Documents/GitHub/Programming_Basics_for_ML/workbooks/013_arrays_and_numpy_sol.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(\u001b[39m\"\u001b[39;49m\u001b[39m../../data/sportsref_download.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akeem/Documents/GitHub/Programming_Basics_for_ML/workbooks/013_arrays_and_numpy_sol.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#df = pd.read_excel(\"../data/sportsref_download.xlsx\", header=1)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akeem/Documents/GitHub/Programming_Basics_for_ML/workbooks/013_arrays_and_numpy_sol.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/io/excel/_base.py:482\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    481\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(io, storage_options\u001b[39m=\u001b[39;49mstorage_options, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[1;32m    483\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[1;32m    484\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    485\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/io/excel/_base.py:1652\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m     ext \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxls\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1651\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1652\u001b[0m     ext \u001b[39m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1653\u001b[0m         content_or_path\u001b[39m=\u001b[39;49mpath_or_buffer, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[1;32m   1654\u001b[0m     )\n\u001b[1;32m   1655\u001b[0m     \u001b[39mif\u001b[39;00m ext \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1656\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1657\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExcel file format cannot be determined, you must specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1658\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39man engine manually.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1659\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/io/excel/_base.py:1525\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(content_or_path, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1523\u001b[0m     content_or_path \u001b[39m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1525\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m   1526\u001b[0m     content_or_path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m, storage_options\u001b[39m=\u001b[39;49mstorage_options, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m   1527\u001b[0m ) \u001b[39mas\u001b[39;00m handle:\n\u001b[1;32m   1528\u001b[0m     stream \u001b[39m=\u001b[39m handle\u001b[39m.\u001b[39mhandle\n\u001b[1;32m   1529\u001b[0m     stream\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    866\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/sportsref_download.xlsx'"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"../../data/sportsref_download.xlsx\", header=1)\n",
    "#df = pd.read_excel(\"../data/sportsref_download.xlsx\", header=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 10 10 10 10 10  9  9  9  8  8  8  7  7  7  7  7  6  6  6  6  5  5  5\n",
      "  5  4  4  4  3  2  1  1  7]\n",
      "[[ 2.750e+01  6.000e+00  6.000e+00  0.000e+00  0.000e+00  1.000e+00\n",
      "   2.700e+01  1.200e+01  0.000e+00  0.000e+00  2.390e+00 -1.100e-01\n",
      "   4.500e+00  2.000e+00  5.000e+00  2.500e+01  2.000e+01  4.000e+00\n",
      "   2.700e+01  8.519e+01  1.000e+00  1.000e+00  1.080e+01  1.180e+01\n",
      "   2.100e+02  1.290e+01  1.890e+02  9.370e-01  0.000e+00]\n",
      " [ 2.790e+01  5.000e+00  5.000e+00  0.000e+00  0.000e+00  1.000e+00\n",
      "   2.200e+01  8.000e+00  0.000e+00  0.000e+00  2.130e+00 -6.700e-01\n",
      "   4.400e+00  1.600e+00  6.000e+00  1.900e+01  3.158e+01  2.000e+00\n",
      "   2.000e+01  9.000e+01  0.000e+00  0.000e+00  8.000e+00  8.000e+00\n",
      "   1.750e+02  1.260e+01  1.490e+02  9.460e-01  0.000e+00]\n",
      " [ 2.940e+01  5.000e+00  5.000e+00  0.000e+00  0.000e+00  1.000e+00\n",
      "   2.300e+01  1.300e+01  1.000e+00  0.000e+00  1.940e+00 -2.600e-01\n",
      "   4.600e+00  2.600e+00  8.000e+00  1.700e+01  4.706e+01  2.000e+00\n",
      "   1.700e+01  8.824e+01  1.000e+00  0.000e+00  1.300e+01  8.600e+00\n",
      "   1.680e+02  1.370e+01  1.880e+02  9.310e-01  0.000e+00]\n",
      " [ 2.880e+01  5.000e+00  5.000e+00  0.000e+00  0.000e+00  1.000e+00\n",
      "   2.500e+01  1.100e+01  0.000e+00  0.000e+00  1.830e+00 -9.700e-01\n",
      "   5.000e+00  2.200e+00  6.000e+00  1.600e+01  3.750e+01  1.000e+00\n",
      "   1.600e+01  9.375e+01  1.000e+00  0.000e+00  9.000e+00  1.020e+01\n",
      "   1.740e+02  1.440e+01  1.700e+02  9.350e-01  1.000e+00]\n",
      " [ 2.940e+01  6.000e+00  5.000e+00  1.000e+00  0.000e+00  8.330e-01\n",
      "   2.000e+01  1.800e+01  0.000e+00  0.000e+00  5.300e-01  2.000e-01\n",
      "   3.330e+00  3.000e+00  4.000e+00  2.200e+01  1.818e+01  8.000e+00\n",
      "   2.600e+01  6.923e+01  0.000e+00  0.000e+00  1.330e+01  1.200e+01\n",
      "   2.180e+02  9.200e+00  1.670e+02  8.920e-01  0.000e+00]\n",
      " [ 2.910e+01  6.000e+00  4.000e+00  0.000e+00  2.000e+00  8.330e-01\n",
      "   2.600e+01  1.600e+01  0.000e+00  0.000e+00  1.330e+00 -3.300e-01\n",
      "   4.330e+00  2.670e+00  3.000e+00  2.100e+01  1.429e+01  5.000e+00\n",
      "   1.700e+01  7.059e+01  2.000e+00  2.000e+00  9.000e+00  1.070e+01\n",
      "   1.830e+02  1.420e+01  1.650e+02  9.030e-01  0.000e+00]\n",
      " [ 2.830e+01  6.000e+00  4.000e+00  1.000e+00  1.000e+00  7.500e-01\n",
      "   1.800e+01  1.100e+01  1.000e+00  0.000e+00  8.100e-01 -5.300e-01\n",
      "   3.000e+00  1.830e+00  5.000e+00  1.800e+01  2.778e+01  2.000e+00\n",
      "   1.600e+01  8.750e+01  0.000e+00  0.000e+00  6.000e+00  6.700e+00\n",
      "   1.980e+02  9.100e+00  1.870e+02  9.410e-01  0.000e+00]\n",
      " [ 2.800e+01  6.000e+00  4.000e+00  1.000e+00  1.000e+00  7.500e-01\n",
      "   2.100e+01  1.500e+01  0.000e+00  0.000e+00  1.310e+00  3.100e-01\n",
      "   3.500e+00  2.500e+00  5.000e+00  1.700e+01  2.941e+01  4.000e+00\n",
      "   1.900e+01  7.895e+01  1.000e+00  1.000e+00  9.300e+00  9.000e+00\n",
      "   2.120e+02  9.900e+00  1.770e+02  9.150e-01  1.000e+00]\n",
      " [ 2.620e+01  7.000e+00  4.000e+00  2.000e+00  1.000e+00  6.430e-01\n",
      "   1.500e+01  1.800e+01  0.000e+00  0.000e+00 -7.900e-01 -3.600e-01\n",
      "   2.140e+00  2.570e+00  3.000e+00  2.600e+01  1.154e+01  5.000e+00\n",
      "   2.300e+01  7.826e+01  0.000e+00  1.000e+00  1.000e+01  1.090e+01\n",
      "   1.890e+02  7.900e+00  2.200e+02  9.180e-01  0.000e+00]\n",
      " [ 2.860e+01  6.000e+00  4.000e+00  2.000e+00  0.000e+00  6.670e-01\n",
      "   2.000e+01  1.400e+01  0.000e+00  0.000e+00  6.000e-01 -4.100e-01\n",
      "   3.330e+00  2.330e+00  5.000e+00  2.000e+01  2.500e+01  2.000e+00\n",
      "   1.400e+01  8.571e+01  1.000e+00  1.000e+00  8.000e+00  1.000e+01\n",
      "   1.660e+02  1.200e+01  1.680e+02  9.170e-01  1.000e+00]\n",
      " [ 2.600e+01  6.000e+00  4.000e+00  2.000e+00  0.000e+00  6.670e-01\n",
      "   1.900e+01  1.500e+01  0.000e+00  0.000e+00  3.000e-01 -3.700e-01\n",
      "   3.170e+00  2.500e+00  5.000e+00  1.900e+01  2.632e+01  4.000e+00\n",
      "   2.100e+01  8.095e+01  0.000e+00  0.000e+00  9.700e+00  9.000e+00\n",
      "   1.600e+02  1.190e+01  2.040e+02  9.260e-01  0.000e+00]\n",
      " [ 2.820e+01  6.000e+00  3.000e+00  1.000e+00  2.000e+00  6.670e-01\n",
      "   2.400e+01  1.600e+01  0.000e+00  1.000e+00  6.600e-01 -5.100e-01\n",
      "   4.000e+00  2.670e+00  4.000e+00  2.100e+01  1.905e+01  1.000e+00\n",
      "   1.500e+01  9.333e+01  0.000e+00  0.000e+00  8.000e+00  1.000e+01\n",
      "   1.980e+02  1.210e+01  1.760e+02  9.090e-01  0.000e+00]\n",
      " [ 2.950e+01  6.000e+00  3.000e+00  2.000e+00  1.000e+00  5.830e-01\n",
      "   1.500e+01  1.500e+01  0.000e+00  0.000e+00 -1.400e-01 -1.400e-01\n",
      "   2.500e+00  2.500e+00  2.000e+00  1.600e+01  1.250e+01  3.000e+00\n",
      "   1.600e+01  8.125e+01  0.000e+00  0.000e+00  7.700e+00  7.700e+00\n",
      "   1.730e+02  8.700e+00  2.100e+02  9.290e-01  2.000e+00]\n",
      " [ 2.680e+01  7.000e+00  3.000e+00  3.000e+00  1.000e+00  5.000e-01\n",
      "   1.900e+01  2.000e+01  1.000e+00  1.000e+00 -3.000e-02  1.100e-01\n",
      "   2.710e+00  2.860e+00  6.000e+00  2.600e+01  2.308e+01  4.000e+00\n",
      "   1.800e+01  7.778e+01  0.000e+00  0.000e+00  9.700e+00  1.310e+01\n",
      "   2.270e+02  8.400e+00  2.240e+02  9.110e-01  0.000e+00]\n",
      " [ 2.690e+01  6.000e+00  3.000e+00  2.000e+00  1.000e+00  5.830e-01\n",
      "   2.000e+01  2.100e+01  0.000e+00  0.000e+00 -7.500e-01 -5.900e-01\n",
      "   3.330e+00  3.500e+00  4.000e+00  2.500e+01  1.600e+01  6.000e+00\n",
      "   2.400e+01  7.500e+01  0.000e+00  0.000e+00  1.480e+01  1.420e+01\n",
      "   1.890e+02  1.060e+01  2.000e+02  8.950e-01  0.000e+00]\n",
      " [ 2.770e+01  6.000e+00  3.000e+00  2.000e+00  1.000e+00  5.830e-01\n",
      "   2.400e+01  2.200e+01  0.000e+00  0.000e+00  7.400e-01  4.100e-01\n",
      "   4.000e+00  3.670e+00  5.000e+00  2.000e+01  2.500e+01  1.000e+01\n",
      "   2.500e+01  6.000e+01  1.000e+00  1.000e+00  1.220e+01  1.220e+01\n",
      "   1.680e+02  1.430e+01  2.010e+02  8.910e-01  0.000e+00]\n",
      " [ 2.890e+01  7.000e+00  3.000e+00  3.000e+00  1.000e+00  5.000e-01\n",
      "   2.100e+01  2.600e+01  0.000e+00  1.000e+00 -2.600e-01  6.000e-01\n",
      "   3.000e+00  3.710e+00  3.000e+00  2.200e+01  1.364e+01  4.000e+00\n",
      "   2.400e+01  8.333e+01  0.000e+00  0.000e+00  9.900e+00  9.600e+00\n",
      "   2.300e+02  9.100e+00  2.070e+02  8.740e-01  0.000e+00]\n",
      " [ 2.720e+01  7.000e+00  3.000e+00  4.000e+00  0.000e+00  4.290e-01\n",
      "   2.000e+01  2.000e+01  0.000e+00  0.000e+00  2.500e-01  2.500e-01\n",
      "   2.860e+00  2.860e+00  7.000e+00  2.200e+01  3.182e+01  4.000e+00\n",
      "   2.300e+01  8.261e+01  0.000e+00  0.000e+00  8.600e+00  8.300e+00\n",
      "   2.150e+02  9.300e+00  2.070e+02  9.030e-01  0.000e+00]\n",
      " [ 2.800e+01  4.000e+00  3.000e+00  1.000e+00  0.000e+00  7.500e-01\n",
      "   1.400e+01  1.100e+01  0.000e+00  0.000e+00  1.470e+00  7.200e-01\n",
      "   3.500e+00  2.750e+00  2.000e+00  9.000e+00  2.222e+01  2.000e+00\n",
      "   1.400e+01  8.571e+01  0.000e+00  0.000e+00  9.300e+00  6.800e+00\n",
      "   1.400e+02  1.000e+01  1.150e+02  9.040e-01  0.000e+00]\n",
      " [ 3.040e+01  6.000e+00  3.000e+00  3.000e+00  0.000e+00  5.000e-01\n",
      "   1.100e+01  1.500e+01  1.000e+00  0.000e+00 -5.000e-01  0.000e+00\n",
      "   1.830e+00  2.500e+00  3.000e+00  1.700e+01  1.765e+01  3.000e+00\n",
      "   2.000e+01  8.500e+01  0.000e+00  0.000e+00  1.070e+01  8.200e+00\n",
      "   1.720e+02  6.400e+00  1.990e+02  9.250e-01  0.000e+00]\n",
      " [ 2.620e+01  5.000e+00  3.000e+00  2.000e+00  0.000e+00  6.000e-01\n",
      "   1.400e+01  1.500e+01  0.000e+00  0.000e+00 -2.500e-01 -5.000e-02\n",
      "   2.800e+00  3.000e+00  3.000e+00  1.300e+01  2.308e+01  6.000e+00\n",
      "   1.800e+01  6.667e+01  0.000e+00  0.000e+00  1.380e+01  1.380e+01\n",
      "   1.570e+02  8.900e+00  1.370e+02  8.910e-01  0.000e+00]\n",
      " [ 2.750e+01  7.000e+00  2.000e+00  4.000e+00  1.000e+00  3.570e-01\n",
      "   2.000e+01  2.400e+01  0.000e+00  0.000e+00  3.600e-01  9.300e-01\n",
      "   2.860e+00  3.430e+00  6.000e+00  2.100e+01  2.857e+01  4.000e+00\n",
      "   2.600e+01  8.462e+01  0.000e+00  0.000e+00  1.290e+01  1.030e+01\n",
      "   2.120e+02  9.400e+00  2.450e+02  9.020e-01  0.000e+00]\n",
      " [ 2.850e+01  4.000e+00  2.000e+00  1.000e+00  1.000e+00  6.250e-01\n",
      "   1.800e+01  1.200e+01  0.000e+00  1.000e+00  1.960e+00  7.100e-01\n",
      "   4.500e+00  3.000e+00  4.000e+00  1.100e+01  3.636e+01  3.000e+00\n",
      "   1.600e+01  8.125e+01  1.000e+00  1.000e+00  1.600e+01  1.600e+01\n",
      "   1.160e+02  1.550e+01  1.340e+02  9.100e-01  0.000e+00]\n",
      " [ 2.820e+01  7.000e+00  2.000e+00  4.000e+00  1.000e+00  3.570e-01\n",
      "   1.300e+01  2.300e+01  0.000e+00  0.000e+00 -1.680e+00 -2.500e-01\n",
      "   1.860e+00  3.290e+00  3.000e+00  2.200e+01  1.364e+01  3.000e+00\n",
      "   2.400e+01  8.750e+01  0.000e+00  0.000e+00  7.900e+00  7.300e+00\n",
      "   2.350e+02  5.500e+00  2.120e+02  8.920e-01  0.000e+00]\n",
      " [ 2.850e+01  7.000e+00  2.000e+00  4.000e+00  1.000e+00  3.570e-01\n",
      "   1.800e+01  2.400e+01  0.000e+00  0.000e+00 -9.800e-01 -1.200e-01\n",
      "   2.570e+00  3.430e+00  3.000e+00  2.100e+01  1.429e+01  2.000e+00\n",
      "   1.600e+01  8.750e+01  0.000e+00  0.000e+00  1.690e+01  1.540e+01\n",
      "   1.870e+02  9.600e+00  1.950e+02  8.770e-01  0.000e+00]\n",
      " [ 2.620e+01  6.000e+00  2.000e+00  4.000e+00  0.000e+00  3.330e-01\n",
      "   1.500e+01  1.900e+01  0.000e+00  0.000e+00 -1.120e+00 -4.500e-01\n",
      "   2.500e+00  3.170e+00  5.000e+00  1.900e+01  2.632e+01  4.000e+00\n",
      "   1.800e+01  7.778e+01  0.000e+00  0.000e+00  1.150e+01  1.150e+01\n",
      "   1.800e+02  8.300e+00  1.920e+02  9.010e-01  0.000e+00]\n",
      " [ 2.740e+01  6.000e+00  2.000e+00  4.000e+00  0.000e+00  3.330e-01\n",
      "   1.500e+01  2.300e+01  1.000e+00  0.000e+00 -9.000e-01  2.700e-01\n",
      "   2.500e+00  3.830e+00  2.000e+00  2.200e+01  9.090e+00  3.000e+00\n",
      "   1.900e+01  8.421e+01  1.000e+00  1.000e+00  1.180e+01  1.230e+01\n",
      "   1.800e+02  8.300e+00  2.010e+02  8.860e-01  0.000e+00]\n",
      " [ 2.820e+01  6.000e+00  2.000e+00  4.000e+00  0.000e+00  3.330e-01\n",
      "   1.300e+01  2.000e+01  0.000e+00  0.000e+00 -9.600e-01  2.100e-01\n",
      "   2.170e+00  3.330e+00  0.000e+00  1.400e+01  0.000e+00  3.000e+00\n",
      "   1.500e+01  8.000e+01  1.000e+00  0.000e+00  9.000e+00  8.800e+00\n",
      "   2.080e+02  6.300e+00  2.020e+02  9.010e-01  0.000e+00]\n",
      " [ 2.820e+01  6.000e+00  1.000e+00  4.000e+00  1.000e+00  2.500e-01\n",
      "   1.400e+01  2.000e+01  0.000e+00  0.000e+00 -5.000e-01  5.000e-01\n",
      "   2.330e+00  3.330e+00  4.000e+00  2.100e+01  1.905e+01  7.000e+00\n",
      "   1.700e+01  5.882e+01  0.000e+00  1.000e+00  7.200e+00  1.000e+01\n",
      "   2.180e+02  6.400e+00  1.840e+02  8.910e-01  0.000e+00]\n",
      " [ 2.830e+01  7.000e+00  1.000e+00  6.000e+00  0.000e+00  1.430e-01\n",
      "   1.100e+01  2.500e+01  0.000e+00  0.000e+00 -2.090e+00 -9.000e-02\n",
      "   1.570e+00  3.570e+00  2.000e+00  2.500e+01  8.000e+00  9.000e+00\n",
      "   2.500e+01  6.400e+01  0.000e+00  0.000e+00  7.700e+00  7.400e+00\n",
      "   1.920e+02  5.700e+00  2.010e+02  8.760e-01  0.000e+00]\n",
      " [ 2.780e+01  6.000e+00  0.000e+00  5.000e+00  1.000e+00  8.300e-02\n",
      "   1.200e+01  2.700e+01  0.000e+00  0.000e+00 -2.740e+00 -2.400e-01\n",
      "   2.000e+00  4.500e+00  6.000e+00  2.200e+01  2.727e+01  2.000e+00\n",
      "   2.200e+01  9.091e+01  0.000e+00  0.000e+00  1.000e+01  1.100e+01\n",
      "   1.860e+02  6.500e+00  1.820e+02  8.520e-01  0.000e+00]\n",
      " [ 2.840e+01  6.000e+00  0.000e+00  5.000e+00  1.000e+00  8.300e-02\n",
      "   1.100e+01  2.900e+01  0.000e+00  1.000e+00 -1.980e+00  1.190e+00\n",
      "   1.830e+00  4.830e+00  2.000e+00  1.600e+01  1.250e+01  9.000e+00\n",
      "   1.400e+01  3.571e+01  0.000e+00  1.000e+00  1.300e+01  1.270e+01\n",
      "   1.600e+02  6.900e+00  1.880e+02  8.460e-01  0.000e+00]\n",
      " [ 2.800e+01  6.000e+00  3.000e+00  2.000e+00  1.000e+00  5.490e-01\n",
      "   1.800e+01  1.800e+01        nan        nan        nan        nan\n",
      "         nan        nan  4.000e+00  2.000e+01  2.096e+01  4.000e+00\n",
      "   2.000e+01  7.904e+01  0.000e+00  0.000e+00  8.900e+00  8.900e+00\n",
      "   1.870e+02  9.600e+00  1.870e+02  9.040e-01  0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "target_column = np.array(df['PTS'])\n",
    "label_column = np.array(df['Unnamed: 1'])\n",
    "feature_set = np.array(df.drop(columns={'PTS', \"Unnamed: 1\", \"Rk\"}, axis=1))\n",
    "print(target_column)\n",
    "print(feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine arrays, or other data structures, together using several functions, including the zip command. This is a common operation when we are combining data from multiple sources, or when we are combining the target and features together to make a single array. In machine learning work, something like this is pretty common as we want to take an array of predictions and compare it to an array of correct values. Since our sizes are fixed, we know that the values in the array should line up perfectly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 'Florida Panthers')\n",
      "(10, 'Carolina Hurricanes')\n",
      "(10, 'Edmonton Oilers')\n",
      "(10, 'St. Louis Blues')\n",
      "(10, 'Minnesota Wild')\n",
      "(10, 'Washington Capitals')\n",
      "(9, 'Buffalo Sabres')\n",
      "(9, 'Calgary Flames')\n",
      "(9, 'New York Rangers')\n",
      "(8, 'San Jose Sharks')\n",
      "(8, 'Columbus Blue Jackets')\n",
      "(8, 'Pittsburgh Penguins')\n",
      "(7, 'New York Islanders')\n",
      "(7, 'Vancouver Canucks')\n",
      "(7, 'Detroit Red Wings')\n",
      "(7, 'Winnipeg Jets')\n",
      "(7, 'Tampa Bay Lightning')\n",
      "(6, 'Nashville Predators')\n",
      "(6, 'Boston Bruins')\n",
      "(6, 'Dallas Stars')\n",
      "(6, 'New Jersey Devils')\n",
      "(5, 'Anaheim Ducks')\n",
      "(5, 'Philadelphia Flyers')\n",
      "(5, 'Toronto Maple Leafs')\n",
      "(5, 'Seattle Kraken')\n",
      "(4, 'Ottawa Senators')\n",
      "(4, 'Colorado Avalanche')\n",
      "(4, 'Vegas Golden Knights')\n",
      "(3, 'Los Angeles Kings')\n",
      "(2, 'Montreal Canadiens')\n",
      "(1, 'Chicago Blackhawks')\n",
      "(1, 'Arizona Coyotes')\n",
      "(7, 'League Average')\n"
     ]
    }
   ],
   "source": [
    "# combine arrays\n",
    "combined = zip(target_column, label_column)\n",
    "for item in combined:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Dimensional Arrays\n",
    "\n",
    "A multi-dimensional array is an array that has more than one dimension, and is also known as a matrix when there are two dimensions, and a tensor when there are three or more dimensions. Arrays that are in two or more dimensions are commonly used to create a data structure that mirrors a dataframe, or to encode the data for an image. \n",
    "\n",
    "![3d Array](../../images/3d_array.webp \"3d Array\")\n",
    "![3d Array](../images/3d_array.webp \"3d Array\")\n",
    "\n",
    "### Multi-Dimensional Array Usage\n",
    "\n",
    "We can access items in a multi-dimensional array by specifying the index of each dimension, separated by commas. For example, if we have a two-dimensional array, we can access the item in the first row and second column by using the index [0, 1]. If we have a three-dimensional array, we can access the item in the first row, second column, and third dimension by using the index [0, 1, 2]. Row is the first digit, column the second, and \"depth\" or \"dimension\" the third."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "array2d1 = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "print(array2d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.750e+01  6.000e+00  6.000e+00  0.000e+00  0.000e+00  1.000e+00\n",
      "   2.700e+01  1.200e+01  0.000e+00  0.000e+00  2.390e+00 -1.100e-01\n",
      "   4.500e+00  2.000e+00  5.000e+00  2.500e+01  2.000e+01  4.000e+00\n",
      "   2.700e+01  8.519e+01  1.000e+00  1.000e+00  1.080e+01  1.180e+01\n",
      "   2.100e+02  1.290e+01  1.890e+02  9.370e-01  0.000e+00]\n",
      " [ 2.790e+01  5.000e+00  5.000e+00  0.000e+00  0.000e+00  1.000e+00\n",
      "   2.200e+01  8.000e+00  0.000e+00  0.000e+00  2.130e+00 -6.700e-01\n",
      "   4.400e+00  1.600e+00  6.000e+00  1.900e+01  3.158e+01  2.000e+00\n",
      "   2.000e+01  9.000e+01  0.000e+00  0.000e+00  8.000e+00  8.000e+00\n",
      "   1.750e+02  1.260e+01  1.490e+02  9.460e-01  0.000e+00]\n",
      " [ 2.940e+01  5.000e+00  5.000e+00  0.000e+00  0.000e+00  1.000e+00\n",
      "   2.300e+01  1.300e+01  1.000e+00  0.000e+00  1.940e+00 -2.600e-01\n",
      "   4.600e+00  2.600e+00  8.000e+00  1.700e+01  4.706e+01  2.000e+00\n",
      "   1.700e+01  8.824e+01  1.000e+00  0.000e+00  1.300e+01  8.600e+00\n",
      "   1.680e+02  1.370e+01  1.880e+02  9.310e-01  0.000e+00]\n",
      " [ 2.880e+01  5.000e+00  5.000e+00  0.000e+00  0.000e+00  1.000e+00\n",
      "   2.500e+01  1.100e+01  0.000e+00  0.000e+00  1.830e+00 -9.700e-01\n",
      "   5.000e+00  2.200e+00  6.000e+00  1.600e+01  3.750e+01  1.000e+00\n",
      "   1.600e+01  9.375e+01  1.000e+00  0.000e+00  9.000e+00  1.020e+01\n",
      "   1.740e+02  1.440e+01  1.700e+02  9.350e-01  1.000e+00]\n",
      " [ 2.940e+01  6.000e+00  5.000e+00  1.000e+00  0.000e+00  8.330e-01\n",
      "   2.000e+01  1.800e+01  0.000e+00  0.000e+00  5.300e-01  2.000e-01\n",
      "   3.330e+00  3.000e+00  4.000e+00  2.200e+01  1.818e+01  8.000e+00\n",
      "   2.600e+01  6.923e+01  0.000e+00  0.000e+00  1.330e+01  1.200e+01\n",
      "   2.180e+02  9.200e+00  1.670e+02  8.920e-01  0.000e+00]\n",
      " [ 2.910e+01  6.000e+00  4.000e+00  0.000e+00  2.000e+00  8.330e-01\n",
      "   2.600e+01  1.600e+01  0.000e+00  0.000e+00  1.330e+00 -3.300e-01\n",
      "   4.330e+00  2.670e+00  3.000e+00  2.100e+01  1.429e+01  5.000e+00\n",
      "   1.700e+01  7.059e+01  2.000e+00  2.000e+00  9.000e+00  1.070e+01\n",
      "   1.830e+02  1.420e+01  1.650e+02  9.030e-01  0.000e+00]\n",
      " [ 2.830e+01  6.000e+00  4.000e+00  1.000e+00  1.000e+00  7.500e-01\n",
      "   1.800e+01  1.100e+01  1.000e+00  0.000e+00  8.100e-01 -5.300e-01\n",
      "   3.000e+00  1.830e+00  5.000e+00  1.800e+01  2.778e+01  2.000e+00\n",
      "   1.600e+01  8.750e+01  0.000e+00  0.000e+00  6.000e+00  6.700e+00\n",
      "   1.980e+02  9.100e+00  1.870e+02  9.410e-01  0.000e+00]\n",
      " [ 2.800e+01  6.000e+00  4.000e+00  1.000e+00  1.000e+00  7.500e-01\n",
      "   2.100e+01  1.500e+01  0.000e+00  0.000e+00  1.310e+00  3.100e-01\n",
      "   3.500e+00  2.500e+00  5.000e+00  1.700e+01  2.941e+01  4.000e+00\n",
      "   1.900e+01  7.895e+01  1.000e+00  1.000e+00  9.300e+00  9.000e+00\n",
      "   2.120e+02  9.900e+00  1.770e+02  9.150e-01  1.000e+00]\n",
      " [ 2.620e+01  7.000e+00  4.000e+00  2.000e+00  1.000e+00  6.430e-01\n",
      "   1.500e+01  1.800e+01  0.000e+00  0.000e+00 -7.900e-01 -3.600e-01\n",
      "   2.140e+00  2.570e+00  3.000e+00  2.600e+01  1.154e+01  5.000e+00\n",
      "   2.300e+01  7.826e+01  0.000e+00  1.000e+00  1.000e+01  1.090e+01\n",
      "   1.890e+02  7.900e+00  2.200e+02  9.180e-01  0.000e+00]\n",
      " [ 2.860e+01  6.000e+00  4.000e+00  2.000e+00  0.000e+00  6.670e-01\n",
      "   2.000e+01  1.400e+01  0.000e+00  0.000e+00  6.000e-01 -4.100e-01\n",
      "   3.330e+00  2.330e+00  5.000e+00  2.000e+01  2.500e+01  2.000e+00\n",
      "   1.400e+01  8.571e+01  1.000e+00  1.000e+00  8.000e+00  1.000e+01\n",
      "   1.660e+02  1.200e+01  1.680e+02  9.170e-01  1.000e+00]\n",
      " [ 2.600e+01  6.000e+00  4.000e+00  2.000e+00  0.000e+00  6.670e-01\n",
      "   1.900e+01  1.500e+01  0.000e+00  0.000e+00  3.000e-01 -3.700e-01\n",
      "   3.170e+00  2.500e+00  5.000e+00  1.900e+01  2.632e+01  4.000e+00\n",
      "   2.100e+01  8.095e+01  0.000e+00  0.000e+00  9.700e+00  9.000e+00\n",
      "   1.600e+02  1.190e+01  2.040e+02  9.260e-01  0.000e+00]\n",
      " [ 2.820e+01  6.000e+00  3.000e+00  1.000e+00  2.000e+00  6.670e-01\n",
      "   2.400e+01  1.600e+01  0.000e+00  1.000e+00  6.600e-01 -5.100e-01\n",
      "   4.000e+00  2.670e+00  4.000e+00  2.100e+01  1.905e+01  1.000e+00\n",
      "   1.500e+01  9.333e+01  0.000e+00  0.000e+00  8.000e+00  1.000e+01\n",
      "   1.980e+02  1.210e+01  1.760e+02  9.090e-01  0.000e+00]\n",
      " [ 2.950e+01  6.000e+00  3.000e+00  2.000e+00  1.000e+00  5.830e-01\n",
      "   1.500e+01  1.500e+01  0.000e+00  0.000e+00 -1.400e-01 -1.400e-01\n",
      "   2.500e+00  2.500e+00  2.000e+00  1.600e+01  1.250e+01  3.000e+00\n",
      "   1.600e+01  8.125e+01  0.000e+00  0.000e+00  7.700e+00  7.700e+00\n",
      "   1.730e+02  8.700e+00  2.100e+02  9.290e-01  2.000e+00]\n",
      " [ 2.680e+01  7.000e+00  3.000e+00  3.000e+00  1.000e+00  5.000e-01\n",
      "   1.900e+01  2.000e+01  1.000e+00  1.000e+00 -3.000e-02  1.100e-01\n",
      "   2.710e+00  2.860e+00  6.000e+00  2.600e+01  2.308e+01  4.000e+00\n",
      "   1.800e+01  7.778e+01  0.000e+00  0.000e+00  9.700e+00  1.310e+01\n",
      "   2.270e+02  8.400e+00  2.240e+02  9.110e-01  0.000e+00]\n",
      " [ 2.690e+01  6.000e+00  3.000e+00  2.000e+00  1.000e+00  5.830e-01\n",
      "   2.000e+01  2.100e+01  0.000e+00  0.000e+00 -7.500e-01 -5.900e-01\n",
      "   3.330e+00  3.500e+00  4.000e+00  2.500e+01  1.600e+01  6.000e+00\n",
      "   2.400e+01  7.500e+01  0.000e+00  0.000e+00  1.480e+01  1.420e+01\n",
      "   1.890e+02  1.060e+01  2.000e+02  8.950e-01  0.000e+00]\n",
      " [ 2.770e+01  6.000e+00  3.000e+00  2.000e+00  1.000e+00  5.830e-01\n",
      "   2.400e+01  2.200e+01  0.000e+00  0.000e+00  7.400e-01  4.100e-01\n",
      "   4.000e+00  3.670e+00  5.000e+00  2.000e+01  2.500e+01  1.000e+01\n",
      "   2.500e+01  6.000e+01  1.000e+00  1.000e+00  1.220e+01  1.220e+01\n",
      "   1.680e+02  1.430e+01  2.010e+02  8.910e-01  0.000e+00]\n",
      " [ 2.890e+01  7.000e+00  3.000e+00  3.000e+00  1.000e+00  5.000e-01\n",
      "   2.100e+01  2.600e+01  0.000e+00  1.000e+00 -2.600e-01  6.000e-01\n",
      "   3.000e+00  3.710e+00  3.000e+00  2.200e+01  1.364e+01  4.000e+00\n",
      "   2.400e+01  8.333e+01  0.000e+00  0.000e+00  9.900e+00  9.600e+00\n",
      "   2.300e+02  9.100e+00  2.070e+02  8.740e-01  0.000e+00]\n",
      " [ 2.720e+01  7.000e+00  3.000e+00  4.000e+00  0.000e+00  4.290e-01\n",
      "   2.000e+01  2.000e+01  0.000e+00  0.000e+00  2.500e-01  2.500e-01\n",
      "   2.860e+00  2.860e+00  7.000e+00  2.200e+01  3.182e+01  4.000e+00\n",
      "   2.300e+01  8.261e+01  0.000e+00  0.000e+00  8.600e+00  8.300e+00\n",
      "   2.150e+02  9.300e+00  2.070e+02  9.030e-01  0.000e+00]\n",
      " [ 2.800e+01  4.000e+00  3.000e+00  1.000e+00  0.000e+00  7.500e-01\n",
      "   1.400e+01  1.100e+01  0.000e+00  0.000e+00  1.470e+00  7.200e-01\n",
      "   3.500e+00  2.750e+00  2.000e+00  9.000e+00  2.222e+01  2.000e+00\n",
      "   1.400e+01  8.571e+01  0.000e+00  0.000e+00  9.300e+00  6.800e+00\n",
      "   1.400e+02  1.000e+01  1.150e+02  9.040e-01  0.000e+00]\n",
      " [ 3.040e+01  6.000e+00  3.000e+00  3.000e+00  0.000e+00  5.000e-01\n",
      "   1.100e+01  1.500e+01  1.000e+00  0.000e+00 -5.000e-01  0.000e+00\n",
      "   1.830e+00  2.500e+00  3.000e+00  1.700e+01  1.765e+01  3.000e+00\n",
      "   2.000e+01  8.500e+01  0.000e+00  0.000e+00  1.070e+01  8.200e+00\n",
      "   1.720e+02  6.400e+00  1.990e+02  9.250e-01  0.000e+00]\n",
      " [ 2.620e+01  5.000e+00  3.000e+00  2.000e+00  0.000e+00  6.000e-01\n",
      "   1.400e+01  1.500e+01  0.000e+00  0.000e+00 -2.500e-01 -5.000e-02\n",
      "   2.800e+00  3.000e+00  3.000e+00  1.300e+01  2.308e+01  6.000e+00\n",
      "   1.800e+01  6.667e+01  0.000e+00  0.000e+00  1.380e+01  1.380e+01\n",
      "   1.570e+02  8.900e+00  1.370e+02  8.910e-01  0.000e+00]\n",
      " [ 2.750e+01  7.000e+00  2.000e+00  4.000e+00  1.000e+00  3.570e-01\n",
      "   2.000e+01  2.400e+01  0.000e+00  0.000e+00  3.600e-01  9.300e-01\n",
      "   2.860e+00  3.430e+00  6.000e+00  2.100e+01  2.857e+01  4.000e+00\n",
      "   2.600e+01  8.462e+01  0.000e+00  0.000e+00  1.290e+01  1.030e+01\n",
      "   2.120e+02  9.400e+00  2.450e+02  9.020e-01  0.000e+00]\n",
      " [ 2.850e+01  4.000e+00  2.000e+00  1.000e+00  1.000e+00  6.250e-01\n",
      "   1.800e+01  1.200e+01  0.000e+00  1.000e+00  1.960e+00  7.100e-01\n",
      "   4.500e+00  3.000e+00  4.000e+00  1.100e+01  3.636e+01  3.000e+00\n",
      "   1.600e+01  8.125e+01  1.000e+00  1.000e+00  1.600e+01  1.600e+01\n",
      "   1.160e+02  1.550e+01  1.340e+02  9.100e-01  0.000e+00]\n",
      " [ 2.820e+01  7.000e+00  2.000e+00  4.000e+00  1.000e+00  3.570e-01\n",
      "   1.300e+01  2.300e+01  0.000e+00  0.000e+00 -1.680e+00 -2.500e-01\n",
      "   1.860e+00  3.290e+00  3.000e+00  2.200e+01  1.364e+01  3.000e+00\n",
      "   2.400e+01  8.750e+01  0.000e+00  0.000e+00  7.900e+00  7.300e+00\n",
      "   2.350e+02  5.500e+00  2.120e+02  8.920e-01  0.000e+00]\n",
      " [ 2.850e+01  7.000e+00  2.000e+00  4.000e+00  1.000e+00  3.570e-01\n",
      "   1.800e+01  2.400e+01  0.000e+00  0.000e+00 -9.800e-01 -1.200e-01\n",
      "   2.570e+00  3.430e+00  3.000e+00  2.100e+01  1.429e+01  2.000e+00\n",
      "   1.600e+01  8.750e+01  0.000e+00  0.000e+00  1.690e+01  1.540e+01\n",
      "   1.870e+02  9.600e+00  1.950e+02  8.770e-01  0.000e+00]\n",
      " [ 2.620e+01  6.000e+00  2.000e+00  4.000e+00  0.000e+00  3.330e-01\n",
      "   1.500e+01  1.900e+01  0.000e+00  0.000e+00 -1.120e+00 -4.500e-01\n",
      "   2.500e+00  3.170e+00  5.000e+00  1.900e+01  2.632e+01  4.000e+00\n",
      "   1.800e+01  7.778e+01  0.000e+00  0.000e+00  1.150e+01  1.150e+01\n",
      "   1.800e+02  8.300e+00  1.920e+02  9.010e-01  0.000e+00]\n",
      " [ 2.740e+01  6.000e+00  2.000e+00  4.000e+00  0.000e+00  3.330e-01\n",
      "   1.500e+01  2.300e+01  1.000e+00  0.000e+00 -9.000e-01  2.700e-01\n",
      "   2.500e+00  3.830e+00  2.000e+00  2.200e+01  9.090e+00  3.000e+00\n",
      "   1.900e+01  8.421e+01  1.000e+00  1.000e+00  1.180e+01  1.230e+01\n",
      "   1.800e+02  8.300e+00  2.010e+02  8.860e-01  0.000e+00]\n",
      " [ 2.820e+01  6.000e+00  2.000e+00  4.000e+00  0.000e+00  3.330e-01\n",
      "   1.300e+01  2.000e+01  0.000e+00  0.000e+00 -9.600e-01  2.100e-01\n",
      "   2.170e+00  3.330e+00  0.000e+00  1.400e+01  0.000e+00  3.000e+00\n",
      "   1.500e+01  8.000e+01  1.000e+00  0.000e+00  9.000e+00  8.800e+00\n",
      "   2.080e+02  6.300e+00  2.020e+02  9.010e-01  0.000e+00]\n",
      " [ 2.820e+01  6.000e+00  1.000e+00  4.000e+00  1.000e+00  2.500e-01\n",
      "   1.400e+01  2.000e+01  0.000e+00  0.000e+00 -5.000e-01  5.000e-01\n",
      "   2.330e+00  3.330e+00  4.000e+00  2.100e+01  1.905e+01  7.000e+00\n",
      "   1.700e+01  5.882e+01  0.000e+00  1.000e+00  7.200e+00  1.000e+01\n",
      "   2.180e+02  6.400e+00  1.840e+02  8.910e-01  0.000e+00]\n",
      " [ 2.830e+01  7.000e+00  1.000e+00  6.000e+00  0.000e+00  1.430e-01\n",
      "   1.100e+01  2.500e+01  0.000e+00  0.000e+00 -2.090e+00 -9.000e-02\n",
      "   1.570e+00  3.570e+00  2.000e+00  2.500e+01  8.000e+00  9.000e+00\n",
      "   2.500e+01  6.400e+01  0.000e+00  0.000e+00  7.700e+00  7.400e+00\n",
      "   1.920e+02  5.700e+00  2.010e+02  8.760e-01  0.000e+00]\n",
      " [ 2.780e+01  6.000e+00  0.000e+00  5.000e+00  1.000e+00  8.300e-02\n",
      "   1.200e+01  2.700e+01  0.000e+00  0.000e+00 -2.740e+00 -2.400e-01\n",
      "   2.000e+00  4.500e+00  6.000e+00  2.200e+01  2.727e+01  2.000e+00\n",
      "   2.200e+01  9.091e+01  0.000e+00  0.000e+00  1.000e+01  1.100e+01\n",
      "   1.860e+02  6.500e+00  1.820e+02  8.520e-01  0.000e+00]\n",
      " [ 2.840e+01  6.000e+00  0.000e+00  5.000e+00  1.000e+00  8.300e-02\n",
      "   1.100e+01  2.900e+01  0.000e+00  1.000e+00 -1.980e+00  1.190e+00\n",
      "   1.830e+00  4.830e+00  2.000e+00  1.600e+01  1.250e+01  9.000e+00\n",
      "   1.400e+01  3.571e+01  0.000e+00  1.000e+00  1.300e+01  1.270e+01\n",
      "   1.600e+02  6.900e+00  1.880e+02  8.460e-01  0.000e+00]\n",
      " [ 2.800e+01  6.000e+00  3.000e+00  2.000e+00  1.000e+00  5.490e-01\n",
      "   1.800e+01  1.800e+01        nan        nan        nan        nan\n",
      "         nan        nan  4.000e+00  2.000e+01  2.096e+01  4.000e+00\n",
      "   2.000e+01  7.904e+01  0.000e+00  0.000e+00  8.900e+00  8.900e+00\n",
      "   1.870e+02  9.600e+00  1.870e+02  9.040e-01  0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing\n",
    "\n",
    "Like lists, we can slice arrays by their index. 2D arrays can be sliced by row, column, or both. 3D arrays can be sliced by row, column, depth, or any combination of the three. We can address the items in the array in two ways:\n",
    "<ul>\n",
    "<li> By specifying the indicies separated by commas. </li>\n",
    "<li> By using a new [] for each dimension. </li>\n",
    "</ul>\n",
    "\n",
    "These two are equivalent, we can use whatever is more convenient. Personally, I think the first is easier to manage when we have multiple dimensions or are doing elaborate slicing. \n",
    "\n",
    "We can also use the colon \":\" in a dimension to get all of the items in that dimension. For example, if we have a 2D array, we can use [0, :] to get all of the items in the first row, and [:, 0] to get all of the items in the first column. We can also use the colon to get a range of items, such as [0:2, 0:2] to get the first two rows and columns. As well, the -1 (or other negative) index can be used to get the last item, or items counting in from the end.\n",
    "\n",
    "![Numpy Indexing](../../images/numpy_indexing.png \"Numpy Indexing\")\n",
    "![Numpy Indexing](../images/numpy_indexing.png \"Numpy Indexing\")\n",
    "\n",
    "With the examples from above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6])"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Row 1\n",
    "array2d1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6])"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Row 1, all columns\n",
    "array2d1[1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The second item in the second column\n",
    "array2d1[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The second item in the second column\n",
    "array2d1[:,1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also the second item in the second column\n",
    "array2d1[1:2,1:2][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also the second item in the second column\n",
    "array2d1[-2][-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Do some slicing and dicing on the feature set array. \n",
    "<ol>\n",
    "<li> Get the first 5 columns. </li>\n",
    "<li> Get the first 5 columns for the bottom 10 teams. </li>\n",
    "<li> Get every third team GF. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.5,  6. ,  6. ,  0. ,  0. ],\n",
       "       [27.9,  5. ,  5. ,  0. ,  0. ],\n",
       "       [29.4,  5. ,  5. ,  0. ,  0. ],\n",
       "       [28.8,  5. ,  5. ,  0. ,  0. ],\n",
       "       [29.4,  6. ,  5. ,  1. ,  0. ],\n",
       "       [29.1,  6. ,  4. ,  0. ,  2. ],\n",
       "       [28.3,  6. ,  4. ,  1. ,  1. ],\n",
       "       [28. ,  6. ,  4. ,  1. ,  1. ],\n",
       "       [26.2,  7. ,  4. ,  2. ,  1. ],\n",
       "       [28.6,  6. ,  4. ,  2. ,  0. ],\n",
       "       [26. ,  6. ,  4. ,  2. ,  0. ],\n",
       "       [28.2,  6. ,  3. ,  1. ,  2. ],\n",
       "       [29.5,  6. ,  3. ,  2. ,  1. ],\n",
       "       [26.8,  7. ,  3. ,  3. ,  1. ],\n",
       "       [26.9,  6. ,  3. ,  2. ,  1. ],\n",
       "       [27.7,  6. ,  3. ,  2. ,  1. ],\n",
       "       [28.9,  7. ,  3. ,  3. ,  1. ],\n",
       "       [27.2,  7. ,  3. ,  4. ,  0. ],\n",
       "       [28. ,  4. ,  3. ,  1. ,  0. ],\n",
       "       [30.4,  6. ,  3. ,  3. ,  0. ],\n",
       "       [26.2,  5. ,  3. ,  2. ,  0. ],\n",
       "       [27.5,  7. ,  2. ,  4. ,  1. ],\n",
       "       [28.5,  4. ,  2. ,  1. ,  1. ],\n",
       "       [28.2,  7. ,  2. ,  4. ,  1. ],\n",
       "       [28.5,  7. ,  2. ,  4. ,  1. ],\n",
       "       [26.2,  6. ,  2. ,  4. ,  0. ],\n",
       "       [27.4,  6. ,  2. ,  4. ,  0. ],\n",
       "       [28.2,  6. ,  2. ,  4. ,  0. ],\n",
       "       [28.2,  6. ,  1. ,  4. ,  1. ],\n",
       "       [28.3,  7. ,  1. ,  6. ,  0. ],\n",
       "       [27.8,  6. ,  0. ,  5. ,  1. ],\n",
       "       [28.4,  6. ,  0. ,  5. ,  1. ],\n",
       "       [28. ,  6. ,  3. ,  2. ,  1. ]])"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 5 columns\n",
    "feature_set[:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.2,  7. ,  2. ,  4. ,  1. ],\n",
       "       [28.5,  7. ,  2. ,  4. ,  1. ],\n",
       "       [26.2,  6. ,  2. ,  4. ,  0. ],\n",
       "       [27.4,  6. ,  2. ,  4. ,  0. ],\n",
       "       [28.2,  6. ,  2. ,  4. ,  0. ],\n",
       "       [28.2,  6. ,  1. ,  4. ,  1. ],\n",
       "       [28.3,  7. ,  1. ,  6. ,  0. ],\n",
       "       [27.8,  6. ,  0. ,  5. ,  1. ],\n",
       "       [28.4,  6. ,  0. ,  5. ,  1. ],\n",
       "       [28. ,  6. ,  3. ,  2. ,  1. ]])"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 5 columns, bottom 10 rows\n",
    "feature_set[-10:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27., 25., 18., 20., 15., 24., 14., 20., 18., 13., 12.])"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every third team points\n",
    "# Every third row\n",
    "# Column number 6\n",
    "feature_set[::3,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slice Steps\n",
    "\n",
    "We can also use a third number in the slice to specify the step size. For example, if we have a 2D array, we can use [0, ::2] to get every other item in the first row, and [:, 0::2] to get every other item in the first column. We can also use the step size to reverse the order of the items, such as [::-1] to get all of the items in reverse order.\n",
    "\n",
    "<b>Note:</b> unless there's some clear reason, we probably don't want to use a step size other than one or have too complex of array slices. It can just become hard to debug and understand if there are long shortcuts slicing up the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 8, 9],\n",
       "       [4, 5, 6],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2d1[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [7, 9]])"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every other row, every other column\n",
    "array2d1[0::2,0::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape and Reshape\n",
    "\n",
    "The shape of an array is the number of elements in each dimension. For example, if we have a two-dimensional array that is 10 rows by 5 columns, the shape of the array is (10, 5). We can get the shape of an array by using the shape attribute, which is a tuple of the dimensions. We can also use the reshape function to change the shape of an array, which is useful when we want to convert a one-dimensional array into a multi-dimensional array, or when we want to change the shape of a multi-dimensional array.\n",
    "\n",
    "Reshape() will force an array into a different shape, assuming the dimensions actually work out. This sounds odd, but we actually use it fairly regularly in machine learning. Two common places where we'll see it are:\n",
    "<ul>\n",
    "<li> We have an individual (usually target) column from a dataframe and we need to make it \"tall\" instead of \"wide\". </li>\n",
    "<li> We have a multi-dimensional array, like an image, that we need to flatten into a single dimension. </li>\n",
    "</ul>\n",
    "\n",
    "These reshaping operations can be a little tricky to wrap your head around, but they do start to make sense with practice. We must make sure that the new shape has the same number of elements as the old shape, or we'll get an error and the operation will fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(33, 29)\n",
      "(33,)\n"
     ]
    }
   ],
   "source": [
    "print(array2d1.shape)\n",
    "print(feature_set.shape)\n",
    "print(target_column.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33,)\n",
      "[12 10 10 10 10 10  9  9  9  8  8  8  7  7  7  7  7  6  6  6  6  5  5  5\n",
      "  5  4  4  4  3  2  1  1  7]\n"
     ]
    }
   ],
   "source": [
    "print(target_column.shape)\n",
    "print(target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the reshape function, one common thing to see is a -1 in one of the dimensions, that means \"however many is needed\". For example, if we have a 100 element array, and we want to reshape it, using reshape(20, -1) will set the output to be 20 rows tall, and determine that the array needs to be 5 columns wide to fit all 100 elements. This is something we use very frequently to prepare one column data - we tell it to be one column wide, and however many rows are needed to fit all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 1)\n",
      "[[12]\n",
      " [10]\n",
      " [10]\n",
      " [10]\n",
      " [10]\n",
      " [10]\n",
      " [ 9]\n",
      " [ 9]\n",
      " [ 9]\n",
      " [ 8]\n",
      " [ 8]\n",
      " [ 8]\n",
      " [ 7]\n",
      " [ 7]\n",
      " [ 7]\n",
      " [ 7]\n",
      " [ 7]\n",
      " [ 6]\n",
      " [ 6]\n",
      " [ 6]\n",
      " [ 6]\n",
      " [ 5]\n",
      " [ 5]\n",
      " [ 5]\n",
      " [ 5]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [ 3]\n",
      " [ 2]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 7]]\n"
     ]
    }
   ],
   "source": [
    "print(target_column.reshape(-1, 1).shape)\n",
    "print(target_column.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shaping Arrays\n",
    "\n",
    "When reshaping arrays we are obviously performing a transformation on the data, changing it from one format to another. The key thing to remember when doing so is that we normally don't really care about looking at the data after it has been reshaped, we are using it for some other function. For example, we might flatten a 2D array to make it into one row of data. As long as we are consistent in exactly how we reshape the data, we will get consistent results. \n",
    "\n",
    "![Array Reshape](../../images/array_reshape.jpeg \"Array Reshape\")\n",
    "![Array Reshape](../images/array_reshape.jpeg \"Array Reshape\")\n",
    "\n",
    "#### Mini-Exercise\n",
    "\n",
    "Fill in the two functions below. Each one should be pretty simple, likely one line. Don't use the flatten() function, use reshape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenArray(array):\n",
    "    # Make the array into one row. \n",
    "    return array.reshape(1, -1)\n",
    "    \n",
    "def unflattenArray(array, num_col):\n",
    "    # Make the array into a 2d array with num_col columns\n",
    "    return array.reshape(-1, num_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These should all work if the functions above do the job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12],\n",
       "       [13, 14, 15, 16]])"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_2D = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12], [13, 14, 15, 16]])\n",
    "array_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]])"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = flattenArray(array_2D)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12],\n",
       "       [13, 14, 15, 16]])"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unflattenArray(tmp, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]])"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2 = flattenArray(unflattenArray(tmp, 8))\n",
    "tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12],\n",
       "       [13, 14, 15, 16]])"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unflattenArray(tmp2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Functions\n",
    "\n",
    "In addition to the array, numpy provides a large number of functions that can be applied to arrays. These functions are largely mathematical in nature, and are used to perform mathematical operations on arrays. The numpy array API page is located here https://numpy.org/doc/1.26/reference/arrays.ndarray.html and is a good reference, and a good reference page to practice referring to for more information. It is fairly clear and easy to read, and has examples. We won't focus on these different functions in detail at all, if we need one we should be able to look up what the function is and the details on how it works. \n",
    "\n",
    "Some common numpy functions include:\n",
    "<ul>\n",
    "<li> np.zeros() - Creates an array of all zeros. </li>\n",
    "<li> np.ones() - Creates an array of all ones. </li>\n",
    "<li> np.full() - Creates an array of a specified size, filled with a specified value. </li>\n",
    "<li> np.random.random() - Creates an array of a specified size, filled with random values between 0 and 1. </li>\n",
    "<li> np.random.normal() - Creates an array of a specified size, filled with random values from a normal distribution with a specified mean and standard deviation. </li>\n",
    "<li> np.random.shuffle() - Shuffles the values in an array. </li>\n",
    "<li> np.random.seed() - Sets the random seed, so that random values are reproducible. </li>\n",
    "<li> np.arange() - Creates an array of a specified size, filled with a sequence of numbers. </li>\n",
    "<li> np.linspace() - Creates an array of a specified size, filled with a sequence of numbers that are evenly spaced between a specified minimum and maximum value. </li>\n",
    "<li> np.reshape() - Reshapes an array into a specified shape. </li>\n",
    "<li> np.concatenate() - Combines two arrays. </li>\n",
    "<li> np.split() - Splits an array into two arrays. </li>\n",
    "<li> np.transpose() - Transposes an array. </li>\n",
    "<li> np.dot() - Performs matrix multiplication on two arrays. </li>\n",
    "<li> np.sum() - Calculates the sum of an array. </li>\n",
    "<li> np.mean() - Calculates the mean of an array. </li>\n",
    "<li> np.std() - Calculates the standard deviation of an array. </li>\n",
    "</ul>\n",
    "\n",
    "Many of these functions are equivalent to ones we used on dataframes or lists to get statistics from the data. Others, such as the ones to initialize an array or do actions like transpose or dot product, are commonly used in the innards of machine learning models - we will later look at using them inside a homemade neural network. These functions tend to be more efficient than their equivalents, so if we already have data in an array, using the built-in functions is preferable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "10\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(array_2D.sum())\n",
    "print(array_2D[0].sum())\n",
    "print(array_2D[:,0].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpose\n",
    "\n",
    "One of the numpy functions that is commonly useful, largely outside of manipulating arrays is the transpose function. This returns a new array that is the transpose of the original array, which means that the rows become columns and the columns become rows. In calculating things, this is useful if we want to do something like average a row, or (how we'll see it later) perform operations between two arrays. It is also useful with some of the information functions, such as describe, especially if we have a large number of columns. The transpose function has a shortcut of T, so we can use array.T to transpose an array.\n",
    "\n",
    "For the describe example below, we can see that the results are now in a datasheet format, that is more useful if we want to do any kind of analysis or automated processing on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "\n",
      "\n",
      "\n",
      "[[ 1  5  9 13]\n",
      " [ 2  6 10 14]\n",
      " [ 3  7 11 15]\n",
      " [ 4  8 12 16]]\n"
     ]
    }
   ],
   "source": [
    "print(array_2D)\n",
    "print(\"\\n\\n\")\n",
    "print(array_2D.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rk</th>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.5</td>\n",
       "      <td>9.380832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.75</td>\n",
       "      <td>16.5</td>\n",
       "      <td>24.25</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>Florida Panthers</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvAge</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.006061</td>\n",
       "      <td>1.030152</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.5</td>\n",
       "      <td>30.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.790569</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.393939</td>\n",
       "      <td>1.675921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OL</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTS</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.606061</td>\n",
       "      <td>2.737921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTS%</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564879</td>\n",
       "      <td>0.256842</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GF</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.060606</td>\n",
       "      <td>4.554801</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.060606</td>\n",
       "      <td>5.279319</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOW</th>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.368902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOL</th>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.368902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRS</th>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091875</td>\n",
       "      <td>1.314231</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>-0.8175</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.935</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOS</th>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.00125</td>\n",
       "      <td>0.49769</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.3625</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GF/G</th>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.07875</td>\n",
       "      <td>0.941926</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.4575</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.625</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA/G</th>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.985313</td>\n",
       "      <td>0.709193</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.43</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>1.720531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPO</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.545455</td>\n",
       "      <td>4.100998</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP%</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.477273</td>\n",
       "      <td>9.614221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.29</td>\n",
       "      <td>20.96</td>\n",
       "      <td>27.27</td>\n",
       "      <td>47.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPA</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>2.323301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPOA</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.545455</td>\n",
       "      <td>4.008514</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PK%</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.102727</td>\n",
       "      <td>11.808809</td>\n",
       "      <td>35.71</td>\n",
       "      <td>77.78</td>\n",
       "      <td>81.25</td>\n",
       "      <td>85.71</td>\n",
       "      <td>93.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.540062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHA</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.540062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIM/G</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.412121</td>\n",
       "      <td>2.636375</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>9.7</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oPIM/G</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.375758</td>\n",
       "      <td>2.429639</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187.363636</td>\n",
       "      <td>26.557506</td>\n",
       "      <td>116.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S%</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.806061</td>\n",
       "      <td>2.767212</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187.363636</td>\n",
       "      <td>26.813963</td>\n",
       "      <td>115.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SV%</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90397</td>\n",
       "      <td>0.02356</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.441674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count unique               top freq        mean        std    min  \\\n",
       "Rk          32.0    NaN               NaN  NaN        16.5   9.380832    1.0   \n",
       "Unnamed: 1    33     33  Florida Panthers    1         NaN        NaN    NaN   \n",
       "AvAge       33.0    NaN               NaN  NaN   28.006061   1.030152   26.0   \n",
       "GP          33.0    NaN               NaN  NaN         6.0   0.790569    4.0   \n",
       "W           33.0    NaN               NaN  NaN         3.0   1.414214    0.0   \n",
       "L           33.0    NaN               NaN  NaN    2.393939   1.675921    0.0   \n",
       "OL          33.0    NaN               NaN  NaN    0.606061   0.609272    0.0   \n",
       "PTS         33.0    NaN               NaN  NaN    6.606061   2.737921    1.0   \n",
       "PTS%        33.0    NaN               NaN  NaN    0.564879   0.256842  0.083   \n",
       "GF          33.0    NaN               NaN  NaN   18.060606   4.554801   11.0   \n",
       "GA          33.0    NaN               NaN  NaN   18.060606   5.279319    8.0   \n",
       "SOW         32.0    NaN               NaN  NaN     0.15625   0.368902    0.0   \n",
       "SOL         32.0    NaN               NaN  NaN     0.15625   0.368902    0.0   \n",
       "SRS         32.0    NaN               NaN  NaN    0.091875   1.314231  -2.74   \n",
       "SOS         32.0    NaN               NaN  NaN    -0.00125    0.49769  -0.97   \n",
       "GF/G        32.0    NaN               NaN  NaN     3.07875   0.941926   1.57   \n",
       "GA/G        32.0    NaN               NaN  NaN    2.985313   0.709193    1.6   \n",
       "PP          33.0    NaN               NaN  NaN    4.090909   1.720531    0.0   \n",
       "PPO         33.0    NaN               NaN  NaN   19.545455   4.100998    9.0   \n",
       "PP%         33.0    NaN               NaN  NaN   21.477273   9.614221    0.0   \n",
       "PPA         33.0    NaN               NaN  NaN    4.090909   2.323301    1.0   \n",
       "PPOA        33.0    NaN               NaN  NaN   19.545455   4.008514   14.0   \n",
       "PK%         33.0    NaN               NaN  NaN   79.102727  11.808809  35.71   \n",
       "SH          33.0    NaN               NaN  NaN    0.333333   0.540062    0.0   \n",
       "SHA         33.0    NaN               NaN  NaN    0.333333   0.540062    0.0   \n",
       "PIM/G       33.0    NaN               NaN  NaN   10.412121   2.636375    6.0   \n",
       "oPIM/G      33.0    NaN               NaN  NaN   10.375758   2.429639    6.7   \n",
       "S           33.0    NaN               NaN  NaN  187.363636  26.557506  116.0   \n",
       "S%          33.0    NaN               NaN  NaN    9.806061   2.767212    5.5   \n",
       "SA          33.0    NaN               NaN  NaN  187.363636  26.813963  115.0   \n",
       "SV%         33.0    NaN               NaN  NaN     0.90397    0.02356  0.846   \n",
       "SO          33.0    NaN               NaN  NaN    0.151515   0.441674    0.0   \n",
       "\n",
       "               25%    50%    75%    max  \n",
       "Rk            8.75   16.5  24.25   32.0  \n",
       "Unnamed: 1     NaN    NaN    NaN    NaN  \n",
       "AvAge         27.5   28.2   28.5   30.4  \n",
       "GP             6.0    6.0    6.0    7.0  \n",
       "W              2.0    3.0    4.0    6.0  \n",
       "L              1.0    2.0    4.0    6.0  \n",
       "OL             0.0    1.0    1.0    2.0  \n",
       "PTS            5.0    7.0    9.0   12.0  \n",
       "PTS%         0.357  0.583   0.75    1.0  \n",
       "GF            14.0   18.0   21.0   27.0  \n",
       "GA            15.0   18.0   22.0   29.0  \n",
       "SOW            0.0    0.0    0.0    1.0  \n",
       "SOL            0.0    0.0    0.0    1.0  \n",
       "SRS        -0.8175   0.11  0.935   2.39  \n",
       "SOS        -0.3625   -0.1   0.28   1.19  \n",
       "GF/G        2.4575   2.93  3.625    5.0  \n",
       "GA/G           2.5   2.93   3.43   4.83  \n",
       "PP             3.0    4.0    5.0    8.0  \n",
       "PPO           17.0   20.0   22.0   26.0  \n",
       "PP%          14.29  20.96  27.27  47.06  \n",
       "PPA            2.0    4.0    5.0   10.0  \n",
       "PPOA          16.0   19.0   23.0   27.0  \n",
       "PK%          77.78  81.25  85.71  93.75  \n",
       "SH             0.0    0.0    1.0    2.0  \n",
       "SHA            0.0    0.0    1.0    2.0  \n",
       "PIM/G          8.6    9.7   12.2   16.9  \n",
       "oPIM/G         8.6   10.0   12.0   16.0  \n",
       "S            172.0  187.0  210.0  235.0  \n",
       "S%             8.3    9.3   12.0   15.5  \n",
       "SA           176.0  189.0  202.0  245.0  \n",
       "SV%          0.891  0.903  0.918  0.946  \n",
       "SO             0.0    0.0    0.0    2.0  "
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Array All Day\n",
    "\n",
    "Complete the Calendar class below. This class is meant to represent a calendar that holds the number of meetings that you have on any given day. \n",
    "\n",
    "The calendar itself should be stored in a 2D array, where each row represents a week, and each column represents a day of the week. The calendar should be initialized to have 0 meetings on every day. This means that the calendar should start life as a 2D array of 0s, with 6 rows and 7 columns. Every time a meeting is added, the value in the array should increase by 1. The purpose of this object is to act as a simple counter for the number of meetings in a day, and provide for simple related functions.\n",
    "\n",
    "#### Output\n",
    "\n",
    "Printing a calendar month should look (some version of) nice. Mine looks like this, with the number of meetings in each spot (I just played around with the number of spaces before/after the values, it only took a few trials. Don't spend forever making sure it lines up perfectly):\n",
    "\n",
    "![Array Calendar](../../images/array_calendar.png \"Array Calendar\")\n",
    "![Array Calendar](../images/array_calendar.png \"Array Calendar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyCalendarMonth():\n",
    "    \n",
    "    days_week = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\n",
    "    months_31 = [\"January\", \"March\", \"May\", \"July\", \"August\", \"October\", \"December\"]\n",
    "    months_30 = [\"April\", \"June\", \"September\", \"November\"]\n",
    "    months_28 = [\"February\"]\n",
    "    months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\",\"October\", \"November\", \"December\"]\n",
    "\n",
    "    def __init__(self, month=\"January\", start_day=\"Monday\"):\n",
    "        self._days = np.zeros((6,7))\n",
    "        self._month = month\n",
    "        self._start_day = start_day\n",
    "        self._first_day_index = self.setFirstDay(start_day)\n",
    "        self.month_length = self.setMonthLength(month)\n",
    "        self.setNone()\n",
    "        #print(self._first_day_index)\n",
    "    \n",
    "    def setMonthLength(self, month):\n",
    "        if month in MyCalendarMonth.months_31:\n",
    "            return 31\n",
    "        elif month in MyCalendarMonth.months_30:\n",
    "            return 30\n",
    "        elif month in MyCalendarMonth.months_28:\n",
    "            return 28\n",
    "        else:\n",
    "            raise ValueError(\"Invalid month\")\n",
    "    \n",
    "    def setFirstDay(self, day):\n",
    "        value = [-1,-1]\n",
    "        offset = MyCalendarMonth.days_week.index(day)\n",
    "        value = [0, offset]\n",
    "        return value\n",
    "    \n",
    "    def addMeeting(self, date):\n",
    "        self.updateCal(date, 1)\n",
    "    def deleteMeeting(self, date):\n",
    "        self.updateCal(date, -1)\n",
    "    \n",
    "    def getCalendar(self):\n",
    "        return self._days\n",
    "    def getWeek(self, week):\n",
    "        return self._days[week]\n",
    "    def printWeek(self, week):\n",
    "        temp_week = self.getWeek(week)\n",
    "        for ind, day in enumerate(temp_week):\n",
    "            print(MyCalendarMonth.days_week[ind], \":\", int(day))\n",
    "    \n",
    "    def getPosition(self, date):\n",
    "        #total_days = date+self._first_day_index[1]\n",
    "        row = (date + self._first_day_index[0]) // 7\n",
    "        col = (date + self._first_day_index[1]) % 7\n",
    "        pos = (row, col)\n",
    "        #print(date, self._first_day_index, pos, total_days)\n",
    "        return pos\n",
    "    def updateCal(self, date, val=1):\n",
    "        print(self._first_day_index, date, self._start_day, val)\n",
    "        spot_row, spot_col = self.getPosition(date)\n",
    "        tmp = self._days[spot_row][spot_col]\n",
    "        tmp += val\n",
    "        if tmp < 0:\n",
    "            tmp = 0\n",
    "        self._days[spot_row][spot_col] = tmp\n",
    "        \n",
    "    def setNone(self):\n",
    "        # set the days before the start and after the end to None\n",
    "        wk1_limit = MyCalendarMonth.days_week.index(self._start_day)\n",
    "        wk6_start = self.getPosition(self.month_length)[1]\n",
    "        #print(wk1_limit, wk6_start, self._first_day_index)\n",
    "        for i in range(0, wk1_limit):\n",
    "            self._days[0][i] = None\n",
    "        for i in range(wk6_start, 7):\n",
    "            #print(i)\n",
    "            self._days[5][i] = None\n",
    "    \n",
    "    def __str__(self):\n",
    "        return_string = self._month + \"\\n\"\n",
    "        return_string += \" \".join(\"S M T W T F S\") + \"\\n\"\n",
    "        for ind, week in enumerate(self._days):\n",
    "            #print(ind, week)\n",
    "            if ind == 0:\n",
    "                start = self._first_day_index[1]\n",
    "                for i in range(0, start):\n",
    "                    return_string += \"    \"\n",
    "                return_string += \" \".join([str(int(week[i]))+\"  \" for i in range(start, 7)])+\"\\n\"\n",
    "            elif ind == 5:\n",
    "                end = self.getPosition(self.month_length)[1]\n",
    "                return_string += \" \".join([str(int(week[i]))+\"  \" for i in range(0, end)])+\"\\n\"\n",
    "            else:\n",
    "                return_string += \" \".join([str(int(day))+\"  \" if day != None else \" \" for day in week]) + \"\\n\"\n",
    "        return return_string\n",
    "\n",
    "    # This will add some meetings randomly, so we can test. \n",
    "    def fakeMeetings(self):\n",
    "        for i in range(0, 42):\n",
    "            self.updateCal(i, np.random.randint(0, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing\n",
    "\n",
    "Let's see if this works... If you used the same method names and parameters as I did, this should work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1 [0, 5]\n"
     ]
    }
   ],
   "source": [
    "a = MyCalendarMonth(start_day=\"Friday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0., nan, nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.getCalendar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5] 0 Friday 0\n",
      "[0, 5] 1 Friday 2\n",
      "[0, 5] 2 Friday 1\n",
      "[0, 5] 3 Friday 2\n",
      "[0, 5] 4 Friday 2\n",
      "[0, 5] 5 Friday 0\n",
      "[0, 5] 6 Friday 0\n",
      "[0, 5] 7 Friday 0\n",
      "[0, 5] 8 Friday 1\n",
      "[0, 5] 9 Friday 2\n",
      "[0, 5] 10 Friday 0\n",
      "[0, 5] 11 Friday 0\n",
      "[0, 5] 12 Friday 2\n",
      "[0, 5] 13 Friday 1\n",
      "[0, 5] 14 Friday 1\n",
      "[0, 5] 15 Friday 2\n",
      "[0, 5] 16 Friday 0\n",
      "[0, 5] 17 Friday 0\n",
      "[0, 5] 18 Friday 0\n",
      "[0, 5] 19 Friday 2\n",
      "[0, 5] 20 Friday 0\n",
      "[0, 5] 21 Friday 1\n",
      "[0, 5] 22 Friday 2\n",
      "[0, 5] 23 Friday 2\n",
      "[0, 5] 24 Friday 1\n",
      "[0, 5] 25 Friday 0\n",
      "[0, 5] 26 Friday 1\n",
      "[0, 5] 27 Friday 1\n",
      "[0, 5] 28 Friday 1\n",
      "[0, 5] 29 Friday 0\n",
      "[0, 5] 30 Friday 2\n",
      "[0, 5] 31 Friday 1\n",
      "[0, 5] 32 Friday 1\n",
      "[0, 5] 33 Friday 0\n",
      "[0, 5] 34 Friday 2\n",
      "[0, 5] 35 Friday 2\n",
      "[0, 5] 36 Friday 2\n",
      "[0, 5] 37 Friday 0\n",
      "[0, 5] 38 Friday 1\n",
      "[0, 5] 39 Friday 0\n",
      "[0, 5] 40 Friday 1\n",
      "[0, 5] 41 Friday 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan,  0.,  2.],\n",
       "       [ 2.,  0.,  0.,  2.,  1.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  2.,  0.,  1.,  2.],\n",
       "       [ 2.,  1.,  0.,  1.,  1.,  1.,  2.],\n",
       "       [ 2.,  1.,  1.,  0.,  2.,  1.,  0.],\n",
       "       [ 0., nan, nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill with dummy data\n",
    "a.fakeMeetings()\n",
    "a.getCalendar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January\n",
      "S   M   T   W   T   F   S\n",
      "                    0   2  \n",
      "2   0   0   2   1   0   1  \n",
      "0   0   0   2   0   1   2  \n",
      "2   1   0   1   1   1   2  \n",
      "2   1   1   0   2   1   0  \n",
      "0  \n",
      "\n",
      "2 5 [0, 2]\n",
      "July\n",
      "S   M   T   W   T   F   S\n",
      "        0   0   0   0   0  \n",
      "0   0   0   0   0   0   0  \n",
      "0   0   0   0   0   0   0  \n",
      "0   0   0   0   0   0   0  \n",
      "0   0   0   0   0   0   0  \n",
      "0   0   0   0   0  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(MyCalendarMonth(\"July\", \"Tuesday\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
