{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines, Transformers, and Geopandas\n",
    "\n",
    "<b>Note:</b> the sklearn transformer and the neural network transformer we'll mention later, and probably several other things named 'transformer' are all different things. \n",
    "\n",
    "## What is an SKLearn Transformer?\n",
    "\n",
    "SKlearn transformers are classes that implement the `fit` and `transform` methods. They are used to preprocess data before feeding it to a model. In normal English, they are a step in data preparation pipelines that apply some type of clean-up step to the data. We use existing transformers all the time to impute, scale, or encode data.\n",
    "\n",
    "We can also write our own custom transformers by extending the `BaseEstimator` and `TransformerMixin` classes from the `sklearn.base` module. This is useful when we need to apply some custom transformation that is not available in the existing transformers. As long as we provide the needed functionality, our custom transformer can be used in the same way as the built-in transformers.\n",
    "\n",
    "## New - Pandas Got Better\n",
    "\n",
    "Recently, I think in 2023, the usability of the pipeline transformers was improved a bit by allowing them to work with pandas dataframes, not only arrays. Dataframes are much easier to use as a human, so this will make steps using and tailoring transformers easier. In the examples later in Machine Learning, we assume we need an array, so we make arrays before starting the pipeline. We now have more flexibility to keep the data in that dataframe format longer, so we can handle it through the pipeline process with more ease. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's a Pipeline?\n",
    "\n",
    "A pipeline in sklearn is a sequence of steps that are applied to the data. In data science, we often need to load a large amount of data, and apply processing steps to that data in bulk to do things like impute, scale, or encode it. The pipeline is a way to automate this process so we can treat it as a group of steps, not a whole bunch of individual actions we need to manage bit by bit. \n",
    "\n",
    "In most cases, we will load our data, send it through the pipleline, and the output of that will go to the predictive modelling algorithm. All the preprocessing steps are done in the pipeline, so we can just focus on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Pipeline Example\n",
    "\n",
    "Here's a simple example of a pipeline - any data fed through this pipeline will have two steps applied to it - first the imputation (filling in blanks), then the scaling (making sure all the data is on the same scale). Each of these steps is a transformer - an object that we can make by extending some classes. These steps can be literally anything that we can imagine, as long as we meet the expectations of what a transformer needs (fit and transform methods) and we accept and return the data in the correct format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "tmp_scale = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"imputer\", tmp_scale),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the make_pipeline function to make a pipeline. It really doesn't matter, I personally never use make_pipeline, but it's there if you want it. The other way has the step name part built in, so that's a bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_for_fake_chumps = make_pipeline(\n",
    "    SimpleImputer(strategy=\"mean\"),\n",
    "    StandardScaler()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indentation\n",
    "\n",
    "This is something of a personal preference, but I find it far easier to read for these types of things where the items are lined up as they are above. VS Code will usually do this pretty well by default, but it really is much more readable than listing them all in a line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare\n",
       "0              1         0       3  22.0      1      0   7.2500\n",
       "1              2         1       1  38.0      1      0  71.2833\n",
       "2              3         1       3  26.0      0      0   7.9250\n",
       "3              4         1       1  35.0      1      0  53.1000\n",
       "4              5         0       3  35.0      0      0   8.0500\n",
       "..           ...       ...     ...   ...    ...    ...      ...\n",
       "886          887         0       2  27.0      0      0  13.0000\n",
       "887          888         1       1  19.0      0      0  30.0000\n",
       "888          889         0       3   NaN      1      2  23.4500\n",
       "889          890         1       1  26.0      0      0  30.0000\n",
       "890          891         0       3  32.0      0      0   7.7500\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/titanic_train.csv\")\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "df.drop(cat_cols, axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.730108</td>\n",
       "      <td>-0.789272</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.592481</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.502445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.726220</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.786845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.722332</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.284663</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.488854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.718444</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.420730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.714556</td>\n",
       "      <td>-0.789272</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.486337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1.714556</td>\n",
       "      <td>-0.789272</td>\n",
       "      <td>-0.369365</td>\n",
       "      <td>-0.207709</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.386671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.718444</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>-0.823344</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.044381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.722332</td>\n",
       "      <td>-0.789272</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>2.008933</td>\n",
       "      <td>-0.176263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.726220</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>-0.284663</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.044381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1.730108</td>\n",
       "      <td>-0.789272</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.177063</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.492378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived    Pclass       Age     SibSp     Parch      Fare\n",
       "0      -1.730108 -0.789272  0.827377 -0.592481  0.432793 -0.473674 -0.502445\n",
       "1      -1.726220  1.266990 -1.566107  0.638789  0.432793 -0.473674  0.786845\n",
       "2      -1.722332  1.266990  0.827377 -0.284663 -0.474545 -0.473674 -0.488854\n",
       "3      -1.718444  1.266990 -1.566107  0.407926  0.432793 -0.473674  0.420730\n",
       "4      -1.714556 -0.789272  0.827377  0.407926 -0.474545 -0.473674 -0.486337\n",
       "..           ...       ...       ...       ...       ...       ...       ...\n",
       "886     1.714556 -0.789272 -0.369365 -0.207709 -0.474545 -0.473674 -0.386671\n",
       "887     1.718444  1.266990 -1.566107 -0.823344 -0.474545 -0.473674 -0.044381\n",
       "888     1.722332 -0.789272  0.827377  0.000000  0.432793  2.008933 -0.176263\n",
       "889     1.726220  1.266990 -1.566107 -0.284663 -0.474545 -0.473674 -0.044381\n",
       "890     1.730108 -0.789272  0.827377  0.177063 -0.474545 -0.473674 -0.492378\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_after = pipe.fit_transform(df)\n",
    "pd.DataFrame(pd_after, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "What happened here? The original data went through the two steps, each of which applied some transformation that changed the data:\n",
    "<ul>\n",
    "<li> The imputer found each empty value, and replaced it with the mean of the column. </li>\n",
    "<li> The scaler did a two step scaling process: </li>\n",
    "    <ul>\n",
    "    <li> The 'fit' part allowed the scaler to learn the mean and standard deviation of the data. </li>\n",
    "    <li> The 'transform' part applied the scaling to the data - setting the values to be \"standardized\" - mean of 0 and standard deviation of 1. </li>\n",
    "    <li> <b> The details of this should be covered in stats, we're just worried about the step here. </b> </li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "### Pipeline Details\n",
    "\n",
    "The pipeline is a pretty simple concept at its core - it is a series of steps where data goes in one end, each step does whatever it does, and the result comes out the end. Each pipeline step has two parts defined:\n",
    "<ul>\n",
    "<li> Name - this is how we refer to the step. When making more complex pipelines, we may need this. We can also grab a step by name. </li>\n",
    "<li> Action - this is the transformer that is applied to the data. Any configuration goes in the constructor call here. </li>\n",
    "</ul>\n",
    "\n",
    "Once created, it does those steps to that data in that order. This is really useful in a real life scenario where we likely have lots of data either in an incoming flow or regular batches to be processed. If we make a pipeline, then all the processing is handled there - we can capture the data in its original format and trust that our pipeline will do the right thing to it.\n",
    "\n",
    "<b>Note:</b> there are ways to have a smarter pipeline, that can do things like process part of the data in one way and part in another (like discreet and continuous data) - that uses the same pipeline framework, but with a couple of slightly more complex tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imputer': SimpleImputer(), 'scaler': StandardScaler()}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Make a Simple Pipeline\n",
    "\n",
    "Make a pipeline for the titanic data. Try to have it do the following things:\n",
    "<ul>\n",
    "<li> Fill in missing values with the median value of that column. (Impute) </li>\n",
    "<li> Scale the data so all the columns are on the same scale. (Use Min-max scaler) </li>\n",
    "</ul>\n",
    "\n",
    "If you're feeling ok here, try to incorporate some other steps. Most work with little to no modifications to the code you need to write. If you search for \"sklearn pipeline\" the documentation page has a link to a User Guide, which is a pretty good article with examples, there are some different transformers in there that you can try out. You can also just google \"sklearn pipeline transformers\" and find one that you can try. For the most part, these are all related to preparing data for ML modeling, so the details aren't something we have worried about yet, but the act of using the transformers is identical no matter what they actually do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do it. \n",
    "pipe_titanic2 = pipeline.Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0.985393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.355056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.296306</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.302247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.115730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409399</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409399</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.366292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.761247</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0.847191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.597889</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.126872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.768539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.748681</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.076123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>0.886517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572757</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.358427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497361</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.262527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass       Age  SibSp     Parch      Fare\n",
       "877     0.985393       0.0     1.0  0.233476  0.000  0.000000  0.015412\n",
       "316     0.355056       1.0     0.5  0.296306  0.125  0.000000  0.050749\n",
       "269     0.302247       1.0     0.0  0.434531  0.000  0.000000  0.264739\n",
       "103     0.115730       0.0     1.0  0.409399  0.000  0.000000  0.016892\n",
       "872     0.979775       0.0     0.0  0.409399  0.000  0.000000  0.009759\n",
       "326     0.366292       0.0     1.0  0.761247  0.000  0.000000  0.012175\n",
       "754     0.847191       1.0     0.5  0.597889  0.125  0.333333  0.126872\n",
       "684     0.768539       0.0     0.5  0.748681  0.125  0.166667  0.076123\n",
       "789     0.886517       0.0     0.0  0.572757  0.000  0.000000  0.154588\n",
       "319     0.358427       1.0     0.0  0.497361  0.125  0.166667  0.262527"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_res2 = pipe_titanic2.fit_transform(df)\n",
    "pd.DataFrame(titanic_res2, columns=df.columns).sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Do I Care?\n",
    "\n",
    "For the moment, we don't need to care about the details of those steps, but we do want to use those mechanics to do our work. The steps that the pipeline does can be anything we want, so if we have some spatial cleanup, we can make a transformer to do that, and add it to the pipeline!\n",
    "\n",
    "In machine learning later on, we will use variations of these pipelines to load most of the data we use. It is even more seamless there, we load the data, then the pipeline feeds the output directly into the modelling algorithm - that wall of numbers version above is hidden from us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Creation Options\n",
    "\n",
    "There are a few ways to make a pipeline, and in general pipeline components can be connected together and swapped out as needed. This leans heavily on the duck typing pattern of thought we've been getting used to - we can swap things around, as long as it does what is required of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Can Transformers Do?\n",
    "\n",
    "Pretty much anything you want, some common examples include:\n",
    "<ul>\n",
    "<li> Imputing missing values </li>\n",
    "<li> Scaling numerical features </li>\n",
    "<li> Encoding categorical features </li>\n",
    "<li> Extracting features from text </li>\n",
    "<li> Reducing dimensionality </li>\n",
    "</ul>\n",
    "\n",
    "Basically anything we can express in a statement of \"change the data in this way\" can be a transformer.\n",
    "\n",
    "### And How Do They Do It?\n",
    "\n",
    "A transfomer is a pretty simple concept. It has two main methods:\n",
    "<ul>\n",
    "<li> `fit` - This method is used to learn the parameters of the transformation. For example, if we are scaling numerical features, the `fit` method will calculate the mean and standard deviation of each feature. </li>\n",
    "    <ul>\n",
    "    <li> In many cases, the `fit` method does nothing, it just returns 'self', but it is still required to be there. </li>\n",
    "    <li> If we were imputing and inserting 'median' for missing values, this step would calculate the median of each feature. </li>\n",
    "    </ul>\n",
    "<li> `transform` - This method is used to apply the transformation to the data. For example, if we are scaling numerical features, the `transform` method will subtract the mean and divide by the standard deviation. </li>\n",
    "</ul>\n",
    "\n",
    "Each of these methods is automatically called by the sklearn pipeline when we insert them as steps. If we have any configuration, such as the number of features to extract or the method of scaling, we can pass these as arguments to the transformer's `__init__` method.\n",
    "\n",
    "### Making a Customized Transformer\n",
    "\n",
    "As long as we follow these expectations, we can make a pipeline step doing almost anything we want. We need to accept values in an expected format - a 2D array or dataframe, and return the values in that same correct format - the details can vary though, we can move, add, delete or change values, rows, and columns as we need. Each manipulation in the transform steps of transformers is basically a prescribed set of steps we could do to any spreadsheet of data. \n",
    "\n",
    "<b>Note:</b> the X copy thing isn't required, it is there as a safety thing to prevent accidental side effects. It's a generally good (or more accurately, safe) idea, but not a requirement. There's at least one solution below without it. The biggest risk here would be if you were to do something that changed the data in place, and then tried to use the original data later - for example, if your transformer has a sort, you don't want to accidentally sort the original data and then try to use it later. In normal usage in a pipeline, this isn't normally something that comes up. It is possible, and can be very confusing if it does. \n",
    "\n",
    "### Transformer TL;DR\n",
    "\n",
    "So, we can make a transformer to do anything we want, we just need to follow some constraints:\n",
    "<ul>\n",
    "<li> We need to extend the BaseEstimator and TransformerMixin classes. </li>\n",
    "<li> We need to implement the fit and transform methods. </li>\n",
    "<li> We need to accept and return the data in the correct format - a 2D table in either DF or array. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # The fit method typically does nothing for transformers\n",
    "        # This is mainly used when there is a 'configuration' \n",
    "        # step that needs to be done before the transformation\n",
    "        # For example, when scaling data with standardization, \n",
    "        # we'd need the mean and std of the data - that's calculated here.\n",
    "    def transform(self, X):\n",
    "        # Your transformation logic goes here\n",
    "        X_transformed = X.copy()  # Copy the input DataFrame to avoid modifying the original\n",
    "        ############## Your code here ##############\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Custom Transformers\n",
    "\n",
    "Adding a custom transformer to a pipeline is identical to using a premade one - that's one of the big benefits of the interchangeability of objects we have with python, duck typing, and inheritance - we only need to provide a tiny portion of the functionality that differs, not learn and reimplement the entire thing!\n",
    "\n",
    "We must conform strictly to the input and output format, as well as the required methods, but beyond that we can do whatever we want. For this example below, we are adding two steps - the area calculator and the custom one. Each step gets a name to refer to it from here on out, and each init call can contain any arguments that we need or want to provide for configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class areaGenerator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X[\"area\"] = self.area\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointGenerator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lon, lat):\n",
    "        self.lon = lon\n",
    "        self.lat = lat\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed[\"geometry\"] = gpd.points_from_xy(X_transformed[self.lon], X_transformed[self.lat])\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Make a Custom Transformer\n",
    "\n",
    "Make a custom transformer that adds a column to the data. The column should be the product of x and y.\n",
    "\n",
    "If that works, add an optional parameter that allows the user to add a constant that defaults to 1, this constant should be multiplied by the product of x and y.\n",
    "\n",
    "If all that works, add the ability to specify the column names for x and y, and name the output column. \n",
    "\n",
    "<b>Use your transformer by calling fit_transform, as well as in a pipeline.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.627552</td>\n",
       "      <td>-0.050178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.433772</td>\n",
       "      <td>-0.074928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.886112</td>\n",
       "      <td>0.348676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.934905</td>\n",
       "      <td>0.123529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.734506</td>\n",
       "      <td>0.751178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0  0.627552 -0.050178\n",
       "1 -0.433772 -0.074928\n",
       "2 -0.886112  0.348676\n",
       "3  0.934905  0.123529\n",
       "4  0.734506  0.751178"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X, y = make_circles(n_samples=1000, factor=0.5, noise=0.1)\n",
    "df_xy = pd.DataFrame(X, columns=[\"x\", \"y\"])\n",
    "df_xy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make class\n",
    "class XYmultiplier(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, factor=1, x_col=\"x\", y_col=\"y\", out_col=\"out\"):\n",
    "        self.factor = factor\n",
    "        self.x_col = x_col\n",
    "        self.y_col = y_col\n",
    "        self.out_col = out_col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed[self.out_col] = X_transformed[self.x_col] * X_transformed[self.y_col] * self.factor\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.627552</td>\n",
       "      <td>-0.050178</td>\n",
       "      <td>-0.062979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.433772</td>\n",
       "      <td>-0.074928</td>\n",
       "      <td>0.065003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.886112</td>\n",
       "      <td>0.348676</td>\n",
       "      <td>-0.617933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.934905</td>\n",
       "      <td>0.123529</td>\n",
       "      <td>0.230975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.734506</td>\n",
       "      <td>0.751178</td>\n",
       "      <td>1.103490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y       out\n",
       "0  0.627552 -0.050178 -0.062979\n",
       "1 -0.433772 -0.074928  0.065003\n",
       "2 -0.886112  0.348676 -0.617933\n",
       "3  0.934905  0.123529  0.230975\n",
       "4  0.734506  0.751178  1.103490"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use it\n",
    "df_xy1 = XYmultiplier(factor=2).fit_transform(df_xy)\n",
    "df_xy1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.627552</td>\n",
       "      <td>-0.050178</td>\n",
       "      <td>-0.062979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.433772</td>\n",
       "      <td>-0.074928</td>\n",
       "      <td>0.065003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.886112</td>\n",
       "      <td>0.348676</td>\n",
       "      <td>-0.617933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.934905</td>\n",
       "      <td>0.123529</td>\n",
       "      <td>0.230975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.734506</td>\n",
       "      <td>0.751178</td>\n",
       "      <td>1.103490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y       out\n",
       "0  0.627552 -0.050178 -0.062979\n",
       "1 -0.433772 -0.074928  0.065003\n",
       "2 -0.886112  0.348676 -0.617933\n",
       "3  0.934905  0.123529  0.230975\n",
       "4  0.734506  0.751178  1.103490"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipe it\n",
    "xy_pipe1 = pipeline.Pipeline([\n",
    "    (\"xy\", XYmultiplier(factor=2))\n",
    "])\n",
    "df_xy2 = xy_pipe1.fit_transform(df_xy)\n",
    "df_xy2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geopandas and Pipelines\n",
    "\n",
    "Geopandas is built \"on top of\" pandas, adding the ability to handle geospatial data to the already powerful pandas data manipulation library. We can use geopandas dataframes exactly as we would use a regular pandas dataframe, but with the added ability to handle geospatial data. Since geopandas dataframes are just pandas dataframes with some extra functionality, we can use them in sklearn pipelines as well.\n",
    "\n",
    "There's little, if any, difference in when we make data a geodataframe. As a rough rule of thumb, if there's lots of manipulation to do with data, I'll load it as a pandas dataframe and make a geodataframe with that data; if there is not much processing, I'll read it with GeoPandas directly and set the geometry right up front. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field_1</th>\n",
       "      <th>Suite</th>\n",
       "      <th>House Number</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Actual Year Built</th>\n",
       "      <th>Garage</th>\n",
       "      <th>Lot Size</th>\n",
       "      <th>Assessed Value</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3407788</td>\n",
       "      <td>201.0</td>\n",
       "      <td>10111</td>\n",
       "      <td>160 STREET NW</td>\n",
       "      <td>53.54247</td>\n",
       "      <td>-113.59791</td>\n",
       "      <td>BRITANNIA YOUNGSTOWN</td>\n",
       "      <td>1980</td>\n",
       "      <td>False</td>\n",
       "      <td>99.029</td>\n",
       "      <td>55500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2636420</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>53.54485</td>\n",
       "      <td>-113.50787</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>1922</td>\n",
       "      <td>False</td>\n",
       "      <td>1.69</td>\n",
       "      <td>16500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3635417</td>\n",
       "      <td>19</td>\n",
       "      <td>1407</td>\n",
       "      <td>GLASTONBURY BOULEVARD NW</td>\n",
       "      <td>53.49635</td>\n",
       "      <td>-113.6664</td>\n",
       "      <td>GLASTONBURY</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>457.215</td>\n",
       "      <td>403500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3683433</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>53.43562</td>\n",
       "      <td>-113.58603</td>\n",
       "      <td>SOUTH TERWILLEGAR</td>\n",
       "      <td>2008</td>\n",
       "      <td>False</td>\n",
       "      <td>3.061</td>\n",
       "      <td>4000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1972487</td>\n",
       "      <td></td>\n",
       "      <td>5223</td>\n",
       "      <td>111A STREET NW</td>\n",
       "      <td>53.48958</td>\n",
       "      <td>-113.51765</td>\n",
       "      <td>LENDRUM PLACE</td>\n",
       "      <td>1966</td>\n",
       "      <td>True</td>\n",
       "      <td>508.346</td>\n",
       "      <td>375500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   field_1  Suite House Number               Street Name  Latitude  \\\n",
       "0  3407788  201.0        10111             160 STREET NW  53.54247   \n",
       "1  2636420                   0                            53.54485   \n",
       "2  3635417     19         1407  GLASTONBURY BOULEVARD NW  53.49635   \n",
       "3  3683433                   0                            53.43562   \n",
       "4  1972487                5223            111A STREET NW  53.48958   \n",
       "\n",
       "    Longitude         Neighbourhood Actual Year Built Garage Lot Size  \\\n",
       "0  -113.59791  BRITANNIA YOUNGSTOWN              1980  False   99.029   \n",
       "1  -113.50787              DOWNTOWN              1922  False     1.69   \n",
       "2   -113.6664           GLASTONBURY              2010   True  457.215   \n",
       "3  -113.58603     SOUTH TERWILLEGAR              2008  False    3.061   \n",
       "4  -113.51765         LENDRUM PLACE              1966   True  508.346   \n",
       "\n",
       "  Assessed Value geometry  \n",
       "0          55500     None  \n",
       "1          16500     None  \n",
       "2         403500     None  \n",
       "3           4000     None  \n",
       "4         375500     None  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd_sample = gpd.read_file( \"../data/03_city_edmonton_assessment_sample.csv\", geometry=\"geometry\")\n",
    "gpd_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Suite</th>\n",
       "      <th>House Number</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Actual Year Built</th>\n",
       "      <th>Garage</th>\n",
       "      <th>Lot Size</th>\n",
       "      <th>Assessed Value</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3407788</td>\n",
       "      <td>201.0</td>\n",
       "      <td>10111</td>\n",
       "      <td>160 STREET NW</td>\n",
       "      <td>53.54247</td>\n",
       "      <td>-113.59791</td>\n",
       "      <td>BRITANNIA YOUNGSTOWN</td>\n",
       "      <td>1980</td>\n",
       "      <td>False</td>\n",
       "      <td>99.029</td>\n",
       "      <td>55500</td>\n",
       "      <td>POINT (53.542 -113.598)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2636420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.54485</td>\n",
       "      <td>-113.50787</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>1922</td>\n",
       "      <td>False</td>\n",
       "      <td>1.690</td>\n",
       "      <td>16500</td>\n",
       "      <td>POINT (53.545 -113.508)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3635417</td>\n",
       "      <td>19</td>\n",
       "      <td>1407</td>\n",
       "      <td>GLASTONBURY BOULEVARD NW</td>\n",
       "      <td>53.49635</td>\n",
       "      <td>-113.66640</td>\n",
       "      <td>GLASTONBURY</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>457.215</td>\n",
       "      <td>403500</td>\n",
       "      <td>POINT (53.496 -113.666)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3683433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.43562</td>\n",
       "      <td>-113.58603</td>\n",
       "      <td>SOUTH TERWILLEGAR</td>\n",
       "      <td>2008</td>\n",
       "      <td>False</td>\n",
       "      <td>3.061</td>\n",
       "      <td>4000</td>\n",
       "      <td>POINT (53.436 -113.586)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1972487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5223</td>\n",
       "      <td>111A STREET NW</td>\n",
       "      <td>53.48958</td>\n",
       "      <td>-113.51765</td>\n",
       "      <td>LENDRUM PLACE</td>\n",
       "      <td>1966</td>\n",
       "      <td>True</td>\n",
       "      <td>508.346</td>\n",
       "      <td>375500</td>\n",
       "      <td>POINT (53.490 -113.518)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Suite  House Number               Street Name  Latitude  \\\n",
       "0     3407788  201.0         10111             160 STREET NW  53.54247   \n",
       "1     2636420    NaN             0                       NaN  53.54485   \n",
       "2     3635417     19          1407  GLASTONBURY BOULEVARD NW  53.49635   \n",
       "3     3683433    NaN             0                       NaN  53.43562   \n",
       "4     1972487    NaN          5223            111A STREET NW  53.48958   \n",
       "\n",
       "   Longitude         Neighbourhood  Actual Year Built  Garage  Lot Size  \\\n",
       "0 -113.59791  BRITANNIA YOUNGSTOWN               1980   False    99.029   \n",
       "1 -113.50787              DOWNTOWN               1922   False     1.690   \n",
       "2 -113.66640           GLASTONBURY               2010    True   457.215   \n",
       "3 -113.58603     SOUTH TERWILLEGAR               2008   False     3.061   \n",
       "4 -113.51765         LENDRUM PLACE               1966    True   508.346   \n",
       "\n",
       "   Assessed Value                 geometry  \n",
       "0           55500  POINT (53.542 -113.598)  \n",
       "1           16500  POINT (53.545 -113.508)  \n",
       "2          403500  POINT (53.496 -113.666)  \n",
       "3            4000  POINT (53.436 -113.586)  \n",
       "4          375500  POINT (53.490 -113.518)  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_sample = pd.read_csv(\"../data/03_city_edmonton_assessment_sample.csv\")\n",
    "pandas_sample = gpd.GeoDataFrame(pandas_sample, geometry=gpd.points_from_xy(pandas_sample[\"Latitude\"], pandas_sample[\"Longitude\"]))\n",
    "pandas_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realistic(-ish) Examples\n",
    "\n",
    "Here are a couple of simple examples. The first adds an area column, the second generates points from lat/lon and places that into the geometry column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Spatial Join Transformer\n",
    "\n",
    "In this example, we can use a spatial join to connect two datasets based on their location. Specifically, we can use the point position of items in our data to connect with the area polygons in a spatial dataset, and get the neighborhood label from that spatial dataset. To make this work, we'll need a few parts:\n",
    "<ul>\n",
    "<li> A geopandas dataframe with the spatial data. This is like a setting or configuration step, so it will be in the constructor. </li>\n",
    "<li> A transformer that can take the 'regular' data we're using, perform the spatial join, and add the result in a new column. </li>\n",
    "</ul>\n",
    "\n",
    "As long as our input and outputs match the sklearn transformer format, we can use this in a pipeline just like any other transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spatial_Joiner( BaseEstimator, TransformerMixin):\n",
    "    # Still must complete. \n",
    "    def __init__(self, other):\n",
    "        self.other = other\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = gpd.sjoin(X, self.other, how=\"left\", op=\"contains\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare Data\n",
    "\n",
    "I'll prepare the data here. The main thing is to ensure that geometry has properly captured the spatial data from the file. In this example, each column requires a little processing to get it into the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "booze = gpd.read_file('../data/Alcohol_Sales_Licences.csv', crs=6933)\n",
    "booze['geometry'] = gpd.points_from_xy(booze['Longitude'], booze['Latitude'])\n",
    "booze.set_geometry('geometry', inplace=True, crs=6933)\n",
    "\n",
    "hoods = gpd.read_file('../data/Neighbourhood_Boundaries.csv')\n",
    "hoods[\"geometry\"] = gpd.GeoSeries.from_wkt(hoods[\"geom\"])\n",
    "hoods.set_geometry(\"geometry\", inplace=True, crs=6933)\n",
    "hoods.drop(\"geom\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akeem/anaconda3/envs/ml_env/lib/python3.10/site-packages/sklearn/base.py:859: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighbourhood Number</th>\n",
       "      <th>Friendly Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>Name</th>\n",
       "      <th>Business Description</th>\n",
       "      <th>Category</th>\n",
       "      <th>Zoning</th>\n",
       "      <th>Address</th>\n",
       "      <th>Neighbourhood ID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>4014</td>\n",
       "      <td>Anthony Henday South</td>\n",
       "      <td>This non-residential neighbourhood forms part ...</td>\n",
       "      <td>MULTIPOLYGON (((-113.517 53.430, -113.517 53.4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>6700</td>\n",
       "      <td>Strathcona Industrial Park</td>\n",
       "      <td>This non-residential neighbourhood is largely ...</td>\n",
       "      <td>MULTIPOLYGON (((-113.466 53.483, -113.466 53.4...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>BREAKTHRU BEVERAGE</td>\n",
       "      <td>Sales and distribution of wine, spirits &amp; beer...</td>\n",
       "      <td>Alcohol Sales (Consumption Off Premises)</td>\n",
       "      <td>IB</td>\n",
       "      <td>9523 - 41 AVENUE NW</td>\n",
       "      <td>6700</td>\n",
       "      <td>53.475887100843806</td>\n",
       "      <td>-113.4764059</td>\n",
       "      <td>POINT (-113.476405893107 53.475887100844)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1150</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>Oliver is one of Edmonton's oldest neighbourho...</td>\n",
       "      <td>MULTIPOLYGON (((-113.510 53.540, -113.510 53.5...</td>\n",
       "      <td>138.0</td>\n",
       "      <td>LIQUOR HOUSE</td>\n",
       "      <td>Liquor Store - Sale of liquor and related prod...</td>\n",
       "      <td>Alcohol Sales (Consumption Off Premises)</td>\n",
       "      <td>DC1</td>\n",
       "      <td>11730 - JASPER AVENUE NW</td>\n",
       "      <td>1150</td>\n",
       "      <td>53.541421385299145</td>\n",
       "      <td>-113.5240591</td>\n",
       "      <td>POINT (-113.524059079928 53.541421385299)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>4650</td>\n",
       "      <td>Winterburn Industrial Area East</td>\n",
       "      <td>This non-residential neighbourhood is largely ...</td>\n",
       "      <td>MULTIPOLYGON (((-113.669 53.541, -113.686 53.5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2060</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>One of the City's smaller neighbourhoods, Bell...</td>\n",
       "      <td>MULTIPOLYGON (((-113.449 53.565, -113.452 53.5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>6350</td>\n",
       "      <td>Kenilworth</td>\n",
       "      <td>Kenilworth lies in the City's southeast, immed...</td>\n",
       "      <td>MULTIPOLYGON (((-113.443 53.518, -113.443 53.5...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>TOPS LIQUOR</td>\n",
       "      <td>Liquor Store</td>\n",
       "      <td>Alcohol Sales (Consumption Off Premises)</td>\n",
       "      <td>CSC</td>\n",
       "      <td>7440 - 82 AVENUE NW</td>\n",
       "      <td>6350</td>\n",
       "      <td>53.51835637870328</td>\n",
       "      <td>-113.4418005</td>\n",
       "      <td>POINT (-113.441800520125 53.518356378703)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1280</td>\n",
       "      <td>Yellowhead Corridor West</td>\n",
       "      <td>This non-residential neighbourhood is limited ...</td>\n",
       "      <td>MULTIPOLYGON (((-113.537 53.583, -113.541 53.5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4350</td>\n",
       "      <td>Norwester Industrial</td>\n",
       "      <td>This non-residential neighbourhood is largely ...</td>\n",
       "      <td>MULTIPOLYGON (((-113.603 53.567, -113.603 53.5...</td>\n",
       "      <td>212.0</td>\n",
       "      <td>WILLOW PARK WINES &amp; SPIRITS EDMONTON</td>\n",
       "      <td>WholeSales to Bars and Restaurants - Retail Li...</td>\n",
       "      <td>Alcohol Sales (Consumption Off Premises)</td>\n",
       "      <td>IB</td>\n",
       "      <td>16612 - 114 AVENUE NW</td>\n",
       "      <td>4350</td>\n",
       "      <td>53.564191188959484</td>\n",
       "      <td>-113.6052181</td>\n",
       "      <td>POINT (-113.60521813517 53.564191188959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>6190</td>\n",
       "      <td>Edmonton Research and Development Park</td>\n",
       "      <td>This non-residential neighbourhood is largely ...</td>\n",
       "      <td>MULTIPOLYGON (((-113.480 53.447, -113.480 53.4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>4461</td>\n",
       "      <td>The Hamptons</td>\n",
       "      <td>The Hamptons</td>\n",
       "      <td>MULTIPOLYGON (((-113.677 53.479, -113.677 53.4...</td>\n",
       "      <td>157.0</td>\n",
       "      <td>LIQUOR HOUSE</td>\n",
       "      <td>Sale of liquor and related products</td>\n",
       "      <td>Alcohol Sales (Consumption Off Premises)</td>\n",
       "      <td>CB1</td>\n",
       "      <td>5224 - 199 STREET NW</td>\n",
       "      <td>4461</td>\n",
       "      <td>53.48844228382365</td>\n",
       "      <td>-113.6652184</td>\n",
       "      <td>POINT (-113.665218430896 53.488442283824)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Neighbourhood Number                           Friendly Name  \\\n",
       "314                 4014                    Anthony Henday South   \n",
       "223                 6700              Strathcona Industrial Park   \n",
       "185                 1150                                  Oliver   \n",
       "208                 4650         Winterburn Industrial Area East   \n",
       "63                  2060                                Bellevue   \n",
       "261                 6350                              Kenilworth   \n",
       "263                 1280                Yellowhead Corridor West   \n",
       "79                  4350                    Norwester Industrial   \n",
       "232                 6190  Edmonton Research and Development Park   \n",
       "368                 4461                            The Hamptons   \n",
       "\n",
       "                                           Description  \\\n",
       "314  This non-residential neighbourhood forms part ...   \n",
       "223  This non-residential neighbourhood is largely ...   \n",
       "185  Oliver is one of Edmonton's oldest neighbourho...   \n",
       "208  This non-residential neighbourhood is largely ...   \n",
       "63   One of the City's smaller neighbourhoods, Bell...   \n",
       "261  Kenilworth lies in the City's southeast, immed...   \n",
       "263  This non-residential neighbourhood is limited ...   \n",
       "79   This non-residential neighbourhood is largely ...   \n",
       "232  This non-residential neighbourhood is largely ...   \n",
       "368                                       The Hamptons   \n",
       "\n",
       "                                              geometry  index_right  \\\n",
       "314  MULTIPOLYGON (((-113.517 53.430, -113.517 53.4...          NaN   \n",
       "223  MULTIPOLYGON (((-113.466 53.483, -113.466 53.4...        200.0   \n",
       "185  MULTIPOLYGON (((-113.510 53.540, -113.510 53.5...        138.0   \n",
       "208  MULTIPOLYGON (((-113.669 53.541, -113.686 53.5...          NaN   \n",
       "63   MULTIPOLYGON (((-113.449 53.565, -113.452 53.5...          NaN   \n",
       "261  MULTIPOLYGON (((-113.443 53.518, -113.443 53.5...         80.0   \n",
       "263  MULTIPOLYGON (((-113.537 53.583, -113.541 53.5...          NaN   \n",
       "79   MULTIPOLYGON (((-113.603 53.567, -113.603 53.5...        212.0   \n",
       "232  MULTIPOLYGON (((-113.480 53.447, -113.480 53.4...          NaN   \n",
       "368  MULTIPOLYGON (((-113.677 53.479, -113.677 53.4...        157.0   \n",
       "\n",
       "                                     Name  \\\n",
       "314                                   NaN   \n",
       "223                    BREAKTHRU BEVERAGE   \n",
       "185                          LIQUOR HOUSE   \n",
       "208                                   NaN   \n",
       "63                                    NaN   \n",
       "261                           TOPS LIQUOR   \n",
       "263                                   NaN   \n",
       "79   WILLOW PARK WINES & SPIRITS EDMONTON   \n",
       "232                                   NaN   \n",
       "368                          LIQUOR HOUSE   \n",
       "\n",
       "                                  Business Description  \\\n",
       "314                                                NaN   \n",
       "223  Sales and distribution of wine, spirits & beer...   \n",
       "185  Liquor Store - Sale of liquor and related prod...   \n",
       "208                                                NaN   \n",
       "63                                                 NaN   \n",
       "261                                       Liquor Store   \n",
       "263                                                NaN   \n",
       "79   WholeSales to Bars and Restaurants - Retail Li...   \n",
       "232                                                NaN   \n",
       "368                Sale of liquor and related products   \n",
       "\n",
       "                                     Category Zoning  \\\n",
       "314                                       NaN    NaN   \n",
       "223  Alcohol Sales (Consumption Off Premises)     IB   \n",
       "185  Alcohol Sales (Consumption Off Premises)    DC1   \n",
       "208                                       NaN    NaN   \n",
       "63                                        NaN    NaN   \n",
       "261  Alcohol Sales (Consumption Off Premises)    CSC   \n",
       "263                                       NaN    NaN   \n",
       "79   Alcohol Sales (Consumption Off Premises)     IB   \n",
       "232                                       NaN    NaN   \n",
       "368  Alcohol Sales (Consumption Off Premises)    CB1   \n",
       "\n",
       "                      Address Neighbourhood ID            Latitude  \\\n",
       "314                       NaN              NaN                 NaN   \n",
       "223       9523 - 41 AVENUE NW             6700  53.475887100843806   \n",
       "185  11730 - JASPER AVENUE NW             1150  53.541421385299145   \n",
       "208                       NaN              NaN                 NaN   \n",
       "63                        NaN              NaN                 NaN   \n",
       "261       7440 - 82 AVENUE NW             6350   53.51835637870328   \n",
       "263                       NaN              NaN                 NaN   \n",
       "79      16612 - 114 AVENUE NW             4350  53.564191188959484   \n",
       "232                       NaN              NaN                 NaN   \n",
       "368      5224 - 199 STREET NW             4461   53.48844228382365   \n",
       "\n",
       "        Longitude                                      Point  \n",
       "314           NaN                                        NaN  \n",
       "223  -113.4764059  POINT (-113.476405893107 53.475887100844)  \n",
       "185  -113.5240591  POINT (-113.524059079928 53.541421385299)  \n",
       "208           NaN                                        NaN  \n",
       "63            NaN                                        NaN  \n",
       "261  -113.4418005  POINT (-113.441800520125 53.518356378703)  \n",
       "263           NaN                                        NaN  \n",
       "79   -113.6052181   POINT (-113.60521813517 53.564191188959)  \n",
       "232           NaN                                        NaN  \n",
       "368  -113.6652184  POINT (-113.665218430896 53.488442283824)  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinPipe = pipeline.Pipeline([\n",
    "    (\"joiner\", Spatial_Joiner(other=booze))\n",
    "])\n",
    "tran_join_result = joinPipe.fit_transform(hoods)\n",
    "tran_join_result.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial Transformations\n",
    "\n",
    "With geospatial data, particularly for the things you're likely to be doing, these transformers and piplines can be used to make tools to process the data automatically into a format that provides what you need for analysis. We can create a pipeline that takes in raw data and outputs it in some format that we know we want - the steps to do those transformations are the transformers in the pipeline. Once built, we can process any new data with no additional effort by just running it through the pipeline - this means that we'd never do something like manually manipulate data in Excel or something like that, we'd always use the pipeline to do it for us.\n",
    "\n",
    "For your applications, you'll get some data and the format you need it in might vary, or you likely might need more than one format. For example, if you were displaying some data in Tableau or Power BI, you can take some raw data, run it through a pipeline that calculates whatever values need to be displayed, then output that as a datasource for your visualization. The transformer step might do all kinds of stuff like calculate distance, do spatial joins to get region labels, calculate area, etc... This data can then be fed to the visualization tool, and it can make pretty pictures without having to manipulate data there. There can be multiple pipelines (or outputs) that each prepares one central source of data, automatically, for different purposes.\n",
    "\n",
    "If this sounds similar to some ETL stuff you talked about in the database classes, that's because it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddAreaCalculation( BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed[self.column_name] = X_transformed[\"geometry\"].area\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Do That With Transformers\n",
    "\n",
    "The processing steps above can be replaced with a pipeline containing custom steps in transformers. For the booze, we want to create a point from the lat/lon columns and set that answer into the geometry column. For the area, we want to add an area column.\n",
    "\n",
    "<b>Hint:</b> we can chain transformers together almost any way we want, they can be connected like pipes in almost any configuration. The easy way to do this might not be the most intuitive... \n",
    "\n",
    "![Pipes](../images/pipe.jpg \"Pipes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "booze2 = gpd.read_file('../data/Alcohol_Sales_Licences.csv')\n",
    "hoods2 = gpd.read_file('../data/Neighbourhood_Boundaries.csv')\n",
    "\n",
    "#Make Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformative Thoughts\n",
    "\n",
    "As we make these transformers, there are a few things that we might want to consider more than we would in other scenarios:\n",
    "<ul>\n",
    "<li> Speed - these transfomrations may be run on all data, so efficiency might matter. </li>\n",
    "    <ul>\n",
    "    <li> We should avoid things that are obviously slow, like nested loops. </li>\n",
    "    <li> Vectorization is a good goal - like np operations on arrays. </li>\n",
    "    </ul>\n",
    "<li> Safety - we should be careful to avoid side effects. </li>\n",
    "    <ul>\n",
    "    <li> We should avoid changing the input data in place as it introduces risk. Unlikely, but possible. </li>\n",
    "    <li> If we make a transformer, we have 0 idea where it'll be used, so safety first. </li>\n",
    "    <li> It isn't relevant right now, but it isn't uncommon for us to process some data and send it to a model, then use that data for something else like visualizations or another model. We don't want accidental changes, that are invisible, to the data behind our backs. In most cases, this won't be a real issue, but it is a very hard problem to trouble shoot if it does happen. </li>\n",
    "    </ul>\n",
    "<li> Flexibility - we should make sure that the transformer can handle a variety of data. By defult pipelines can work with data in arrays and dataframs in a way that is more-or-less seamless. We want the same behaviour in most cases. This usually isn't that big of a stretch, most other functions that we might need will work with different data types already, so as long as we don't introduce some object-specific action, we should be ok. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Make Some Transformers\n",
    "\n",
    "For this exercise, create a transformer that adds a new column representing the distance between the two locations in the dataframe. The transformer should take the two columns containing the latitude and longitude of the two locations as input and add a new column with the distance between them.\n",
    "\n",
    "Create a pipeline with transformers that:\n",
    "<ul>\n",
    "<li> Adds a new column with the distance to a set point. </li>\n",
    "<li> Adds a new column with the distance to the nearest point in another dataset. </li>\n",
    "<li> Adds a new column 'geometry' that is the point geometry, from lat and lon. </li>\n",
    "<li> Add a transformer that filters things that are within a set distance of a point. </li>\n",
    "</ul>\n",
    "\n",
    "<b>Editor's Note:</b> I wrote these first, and they ended up being a bit redundant. I just didn't delete these prompts, but there's some overlap with the stuff above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you know what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Playground Number</th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Type</th>\n",
       "      <th>Surface Type</th>\n",
       "      <th>Accessibility</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Maintainer</th>\n",
       "      <th>Redevelopment Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Neighbourhood ID</th>\n",
       "      <th>park_type</th>\n",
       "      <th>User Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12504</td>\n",
       "      <td>631</td>\n",
       "      <td>Queen Alex Spray Park</td>\n",
       "      <td>10722 - 73 AVENUE NW</td>\n",
       "      <td>Spray Deck</td>\n",
       "      <td>Pour In Place Rubber</td>\n",
       "      <td>Wheelchair Accessible</td>\n",
       "      <td>Parks</td>\n",
       "      <td>Parks</td>\n",
       "      <td>2010-09-01</td>\n",
       "      <td>53.509733</td>\n",
       "      <td>-113.507833</td>\n",
       "      <td>5330</td>\n",
       "      <td>spray</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>708289</td>\n",
       "      <td>3677</td>\n",
       "      <td>Cy Becker Spray Park</td>\n",
       "      <td>270 Cy Becker Boulevard NW</td>\n",
       "      <td>Spray Park</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>Wheelchair Accessible</td>\n",
       "      <td>Parks</td>\n",
       "      <td>Parks</td>\n",
       "      <td>2018-09-14</td>\n",
       "      <td>53.634241</td>\n",
       "      <td>-113.407026</td>\n",
       "      <td>2611</td>\n",
       "      <td>spray</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12359</td>\n",
       "      <td>728</td>\n",
       "      <td>King Edward Spray Park</td>\n",
       "      <td>7708 - 85 STREET NW T6C4K9</td>\n",
       "      <td>Spray Deck</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>Wheelchair Accessible</td>\n",
       "      <td>Parks</td>\n",
       "      <td>Parks</td>\n",
       "      <td>2006-09-01</td>\n",
       "      <td>53.513639</td>\n",
       "      <td>-113.460902</td>\n",
       "      <td>6360</td>\n",
       "      <td>spray</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12513</td>\n",
       "      <td>636</td>\n",
       "      <td>Royal Gardens Spray Park</td>\n",
       "      <td>4030 117 Street NW</td>\n",
       "      <td>Spray Deck</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>Wheelchair Accessible</td>\n",
       "      <td>Parks</td>\n",
       "      <td>Parks</td>\n",
       "      <td>2001-09-13</td>\n",
       "      <td>53.478097</td>\n",
       "      <td>-113.535659</td>\n",
       "      <td>5430</td>\n",
       "      <td>spray</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>708360</td>\n",
       "      <td>3684</td>\n",
       "      <td>York Spray Park</td>\n",
       "      <td>5825 140 Avenue NW</td>\n",
       "      <td>Spray Park</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>Wheelchair Accessible</td>\n",
       "      <td>Parks</td>\n",
       "      <td>Parks</td>\n",
       "      <td>2018-09-14</td>\n",
       "      <td>53.602062</td>\n",
       "      <td>-113.431296</td>\n",
       "      <td>2720</td>\n",
       "      <td>spray</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Playground Number                      Name  \\\n",
       "0   12504                631     Queen Alex Spray Park   \n",
       "1  708289               3677      Cy Becker Spray Park   \n",
       "2   12359                728    King Edward Spray Park   \n",
       "3   12513                636  Royal Gardens Spray Park   \n",
       "4  708360               3684           York Spray Park   \n",
       "\n",
       "                      Address        Type          Surface Type  \\\n",
       "0        10722 - 73 AVENUE NW  Spray Deck  Pour In Place Rubber   \n",
       "1  270 Cy Becker Boulevard NW  Spray Park              Concrete   \n",
       "2  7708 - 85 STREET NW T6C4K9  Spray Deck              Concrete   \n",
       "3          4030 117 Street NW  Spray Deck              Concrete   \n",
       "4          5825 140 Avenue NW  Spray Park              Concrete   \n",
       "\n",
       "           Accessibility  Owner Maintainer Redevelopment Date   Latitude  \\\n",
       "0  Wheelchair Accessible  Parks      Parks         2010-09-01  53.509733   \n",
       "1  Wheelchair Accessible  Parks      Parks         2018-09-14  53.634241   \n",
       "2  Wheelchair Accessible  Parks      Parks         2006-09-01  53.513639   \n",
       "3  Wheelchair Accessible  Parks      Parks         2001-09-13  53.478097   \n",
       "4  Wheelchair Accessible  Parks      Parks         2018-09-14  53.602062   \n",
       "\n",
       "    Longitude  Neighbourhood ID park_type User Category  \n",
       "0 -113.507833              5330     spray           NaN  \n",
       "1 -113.407026              2611     spray           NaN  \n",
       "2 -113.460902              6360     spray           NaN  \n",
       "3 -113.535659              5430     spray           NaN  \n",
       "4 -113.431296              2720     spray           NaN  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_play = pd.read_csv(\"../data/playgrounds.csv\")\n",
    "ex_play.drop(columns=[\"Location\", \"Geometry Point\"], inplace=True)\n",
    "ex_play.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set point test\n",
    "nait_lat = 53.57030\n",
    "nait_long = -113.50087\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "wide_to_long() missing 4 required positional arguments: 'df', 'stubnames', 'i', and 'j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m d2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/akeem/Downloads/CH4_Emissions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#d1.reindex(d1[\"Country ID\"], axis=1)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#d1.reset_index(drop=True, inplace=True)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwide_to_long\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m d1\n",
      "\u001b[0;31mTypeError\u001b[0m: wide_to_long() missing 4 required positional arguments: 'df', 'stubnames', 'i', and 'j'"
     ]
    }
   ],
   "source": [
    "#d1 = pd.read_excel(\"/Users/akeem/Downloads/CO2_Emissions.xlsx\")\n",
    "#d2 = pd.read_excel(\"/Users/akeem/Downloads/CH4_Emissions.xlsx\")\n",
    "d1 = pd.read_csv(\"/Users/akeem/Downloads/CO2_Emissions.csv\", encoding=\"latin1\")\n",
    "d2 = pd.read_csv(\"/Users/akeem/Downloads/CH4_Emissions.csv\", encoding=\"latin1\")\n",
    "#d1.reindex(d1[\"Country ID\"], axis=1)\n",
    "#d1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=189, step=1)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_num_cols = []\n",
    "for col in d1.columns:\n",
    "    if type(col) in [int, float]:\n",
    "        d1_num_cols.append(int(col))\n",
    "d1_non_num_cols = [col for col in d1.columns if col not in d1_num_cols]\n",
    "\n",
    "d2_num_cols = []\n",
    "for col in d2.columns:\n",
    "    if type(col) in [int, float]:\n",
    "        d2_num_cols.append(int(col))\n",
    "d2_non_num_cols = [col for col in d2.columns if col not in d2_num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/m8wtcgx57417hx9d_r110ctw0000gn/T/ipykernel_62894/4244771418.py:2: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  d1 = pd.melt(d1, id_vars=\"Country Name\", value_vars=d1_num_cols)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Country Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Country Name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#pd.wide_to_long(d1, stubnames= d1_num_cols, i=d1_non_num_cols, j=\"Year\")\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmelt\u001b[49m\u001b[43m(\u001b[49m\u001b[43md1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCountry Name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md1_num_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m d1\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/core/reshape/melt.py:132\u001b[0m, in \u001b[0;36mmelt\u001b[0;34m(frame, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\u001b[0m\n\u001b[1;32m    130\u001b[0m mdata \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m id_vars:\n\u001b[0;32m--> 132\u001b[0m     id_data \u001b[38;5;241m=\u001b[39m \u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_extension_array_dtype(id_data):\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m K \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/core/frame.py:5685\u001b[0m, in \u001b[0;36mDataFrame.pop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   5644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   5645\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5646\u001b[0m \u001b[38;5;124;03m    Return item and drop from frame. Raise KeyError if not found.\u001b[39;00m\n\u001b[1;32m   5647\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5683\u001b[0m \u001b[38;5;124;03m    3  monkey        NaN\u001b[39;00m\n\u001b[1;32m   5684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/core/generic.py:923\u001b[0m, in \u001b[0;36mNDFrame.pop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m Any:\n\u001b[0;32m--> 923\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m[item]\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Country Name'"
     ]
    }
   ],
   "source": [
    "#pd.wide_to_long(d1, stubnames= d1_num_cols, i=d1_non_num_cols, j=\"Year\")\n",
    "d1 = pd.melt(d1, id_vars=\"Country Name\", value_vars=d1_num_cols)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>...</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>Latest Year</th>\n",
       "      <th>CO2 emissions, latest year</th>\n",
       "      <th>% change since 1990</th>\n",
       "      <th>CO2 emissions \\nper capita, \\nlatest year</th>\n",
       "      <th>Emission Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>9851.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31</td>\n",
       "      <td>CO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Albania</td>\n",
       "      <td>3,101.66</td>\n",
       "      <td>5,166.70</td>\n",
       "      <td>3,311.06</td>\n",
       "      <td>3,235.47</td>\n",
       "      <td>3,500.49</td>\n",
       "      <td>3,477.42</td>\n",
       "      <td>3,341.56</td>\n",
       "      <td>3,426.64</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>5942.57</td>\n",
       "      <td>91.59</td>\n",
       "      <td>2.00</td>\n",
       "      <td>N2O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>63,705.00</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>2000</td>\n",
       "      <td>71593.26</td>\n",
       "      <td>...</td>\n",
       "      <td>2.31</td>\n",
       "      <td>CH4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>Angola</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>2005</td>\n",
       "      <td>27809.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>288.14</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>2000</td>\n",
       "      <td>371.88</td>\n",
       "      <td>29.06</td>\n",
       "      <td>4.89</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country ID              Country      1990      1991      1992      1993  \\\n",
       "0           4          Afghanistan       ...       ...       ...       ...   \n",
       "1           8              Albania  3,101.66  5,166.70  3,311.06  3,235.47   \n",
       "2          12              Algeria       ...       ...       ...       ...   \n",
       "3          24               Angola       ...       ...       ...       ...   \n",
       "4          28  Antigua and Barbuda    288.14       ...       ...       ...   \n",
       "\n",
       "        1994      1995      1996      1997  ... 2014 2015 2016 2017 2018  \\\n",
       "0        ...       ...       ...       ...  ...  ...  ...  ...  ...  ...   \n",
       "1   3,500.49  3,477.42  3,341.56  3,426.64  ...  ...  ...  ...  ...  ...   \n",
       "2  63,705.00       ...       ...       ...  ...  ...  ...  ...  ...  ...   \n",
       "3        ...       ...       ...       ...  ...  ...  ...  ...  ...  ...   \n",
       "4        ...       ...       ...       ...  ...  ...  ...  ...  ...  ...   \n",
       "\n",
       "  Latest Year CO2 emissions, latest year % change since 1990  \\\n",
       "0        2013                    9851.00                 ...   \n",
       "1        2009                    5942.57               91.59   \n",
       "2        2000                   71593.26                 ...   \n",
       "3        2005                   27809.00                 ...   \n",
       "4        2000                     371.88               29.06   \n",
       "\n",
       "  CO2 emissions \\nper capita, \\nlatest year Emission Type  \n",
       "0                                      0.31           CO2  \n",
       "1                                      2.00           N2O  \n",
       "2                                      2.31           CH4  \n",
       "3                                      1.43           NaN  \n",
       "4                                      4.89           NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.pivot(columns = d1_non_num_cols, values = d1_num_cols)\n",
    "d1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
